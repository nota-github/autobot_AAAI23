11/03 02:59:44 AM | args = Namespace(output_dir='result/test/test1', loaded_model_path='result/pruned/cifar10/resnet110/pruned.pt', resume=False, test_only=False, mode='finetune', batch_size=256, nb_batches=100, Mflops_target=None, lr=0.6, momentum=0.9, beta=6, gamma=0.2, gpu='1', num_workers=4, dataset='cifar10', arch='resnet_110', save_plot=False, seed=11, lr_finetuning=0.02, epoch_finetuning=200, wd=0.002, data_dir='./data/cifar10/', print_freq=50, num_classes=10, device_ids=[1], device=device(type='cuda', index=0), name_base='')
11/03 02:59:51 AM | ----------------------------------------
11/03 02:59:51 AM | ==> Building model...
11/03 02:59:51 AM | ----------------------------------------
11/03 02:59:51 AM | ==> Loading weights into the model...
11/03 02:59:51 AM | ----------------------------------------
11/03 02:59:51 AM | ResNet(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(6, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (1): BasicBlock(
      (conv1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(7, 14, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (3): BasicBlock(
      (conv1): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(5, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (4): BasicBlock(
      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (5): BasicBlock(
      (conv1): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(4, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (6): BasicBlock(
      (conv1): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(5, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (7): BasicBlock(
      (conv1): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(7, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(13, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (8): BasicBlock(
      (conv1): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (9): BasicBlock(
      (conv1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(3, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (10): BasicBlock(
      (conv1): Conv2d(16, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(5, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (11): BasicBlock(
      (conv1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (12): BasicBlock(
      (conv1): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(7, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (13): BasicBlock(
      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (14): BasicBlock(
      (conv1): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(3, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (15): BasicBlock(
      (conv1): Conv2d(16, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(6, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (16): BasicBlock(
      (conv1): Conv2d(16, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(7, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (17): BasicBlock(
      (conv1): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 7, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(16, 27, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(27, 28, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock(
      (conv1): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(3, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(9, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(19, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (3): BasicBlock(
      (conv1): Conv2d(32, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(5, 21, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (4): BasicBlock(
      (conv1): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 22, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (5): BasicBlock(
      (conv1): Conv2d(32, 11, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(11, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (6): BasicBlock(
      (conv1): Conv2d(32, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(15, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (7): BasicBlock(
      (conv1): Conv2d(32, 9, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(9, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(9, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (8): BasicBlock(
      (conv1): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(12, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (9): BasicBlock(
      (conv1): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(10, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (10): BasicBlock(
      (conv1): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(10, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (11): BasicBlock(
      (conv1): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (12): BasicBlock(
      (conv1): Conv2d(32, 15, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(15, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(15, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (13): BasicBlock(
      (conv1): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(10, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (14): BasicBlock(
      (conv1): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(12, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (15): BasicBlock(
      (conv1): Conv2d(32, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(8, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (16): BasicBlock(
      (conv1): Conv2d(32, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (17): BasicBlock(
      (conv1): Conv2d(32, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(10, 17, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv2d(32, 62, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(62, 60, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): LambdaLayer()
    )
    (1): BasicBlock(
      (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(33, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (2): BasicBlock(
      (conv1): Conv2d(64, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(23, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (3): BasicBlock(
      (conv1): Conv2d(64, 37, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(37, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(52, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (4): BasicBlock(
      (conv1): Conv2d(64, 30, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(30, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (5): BasicBlock(
      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (6): BasicBlock(
      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(32, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(58, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (7): BasicBlock(
      (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(33, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (8): BasicBlock(
      (conv1): Conv2d(64, 35, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(35, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(35, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (9): BasicBlock(
      (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(32, 57, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(57, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (10): BasicBlock(
      (conv1): Conv2d(64, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(23, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(23, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (11): BasicBlock(
      (conv1): Conv2d(64, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(27, 50, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (12): BasicBlock(
      (conv1): Conv2d(64, 33, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(33, 53, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(53, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (13): BasicBlock(
      (conv1): Conv2d(64, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(25, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(47, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (14): BasicBlock(
      (conv1): Conv2d(64, 36, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(36, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (15): BasicBlock(
      (conv1): Conv2d(64, 18, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(18, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (16): BasicBlock(
      (conv1): Conv2d(64, 31, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(31, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(31, 38, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(38, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
    (17): BasicBlock(
      (conv1): Conv2d(64, 46, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv2): Conv2d(46, 39, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (shortcut): Sequential()
    )
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear): Linear(in_features=64, out_features=10, bias=True)
)
11/03 02:59:54 AM | Epoch[0]
11/03 02:59:54 AM | learning_rate: 0.02
11/03 02:59:55 AM |   (0/196):Loss 0.1748 Prec@1(1,5) 94.14, 100.00
11/03 03:00:00 AM |   (50/196):Loss 0.1830 Prec@1(1,5) 93.86, 99.95
11/03 03:00:06 AM |   (100/196):Loss 0.1515 Prec@1(1,5) 94.90, 99.97
11/03 03:00:11 AM |   (150/196):Loss 0.1372 Prec@1(1,5) 95.35, 99.97
11/03 03:00:19 AM |  * Acc@1 90.340 Acc@5 99.730
11/03 03:00:19 AM | =>Best accuracy 90.340 (at epoch 0)
11/03 03:00:19 AM | ----
11/03 03:00:19 AM | Epoch[1]
11/03 03:00:19 AM | learning_rate: 0.019998766324816605
11/03 03:00:19 AM |   (0/196):Loss 0.0743 Prec@1(1,5) 97.66, 100.00
11/03 03:00:25 AM |   (50/196):Loss 0.0741 Prec@1(1,5) 97.59, 100.00
11/03 03:00:30 AM |   (100/196):Loss 0.0751 Prec@1(1,5) 97.55, 100.00
11/03 03:00:36 AM |   (150/196):Loss 0.0766 Prec@1(1,5) 97.47, 99.99
11/03 03:00:42 AM |  * Acc@1 90.750 Acc@5 99.740
11/03 03:00:43 AM | =>Best accuracy 90.750 (at epoch 1)
11/03 03:00:43 AM | ----
11/03 03:00:43 AM | Epoch[2]
11/03 03:00:43 AM | learning_rate: 0.019995065603657314
11/03 03:00:43 AM |   (0/196):Loss 0.0407 Prec@1(1,5) 98.83, 100.00
11/03 03:00:49 AM |   (50/196):Loss 0.0663 Prec@1(1,5) 97.90, 100.00
11/03 03:00:54 AM |   (100/196):Loss 0.0664 Prec@1(1,5) 97.94, 100.00
11/03 03:01:00 AM |   (150/196):Loss 0.0681 Prec@1(1,5) 97.91, 99.99
11/03 03:01:06 AM |  * Acc@1 91.070 Acc@5 99.650
11/03 03:01:06 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:01:06 AM | ----
11/03 03:01:06 AM | Epoch[3]
11/03 03:01:06 AM | learning_rate: 0.0199888987496197
11/03 03:01:07 AM |   (0/196):Loss 0.0517 Prec@1(1,5) 98.44, 100.00
11/03 03:01:13 AM |   (50/196):Loss 0.0658 Prec@1(1,5) 98.08, 100.00
11/03 03:01:18 AM |   (100/196):Loss 0.0653 Prec@1(1,5) 98.04, 100.00
11/03 03:01:24 AM |   (150/196):Loss 0.0672 Prec@1(1,5) 98.00, 100.00
11/03 03:01:31 AM |  * Acc@1 90.980 Acc@5 99.800
11/03 03:01:31 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:01:31 AM | ----
11/03 03:01:31 AM | Epoch[4]
11/03 03:01:31 AM | learning_rate: 0.019980267284282715
11/03 03:01:31 AM |   (0/196):Loss 0.0493 Prec@1(1,5) 99.22, 100.00
11/03 03:01:37 AM |   (50/196):Loss 0.0640 Prec@1(1,5) 98.19, 100.00
11/03 03:01:42 AM |   (100/196):Loss 0.0643 Prec@1(1,5) 98.16, 100.00
11/03 03:01:48 AM |   (150/196):Loss 0.0656 Prec@1(1,5) 98.09, 100.00
11/03 03:01:55 AM |  * Acc@1 90.670 Acc@5 99.770
11/03 03:01:55 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:01:55 AM | ----
11/03 03:01:55 AM | Epoch[5]
11/03 03:01:55 AM | learning_rate: 0.019969173337331277
11/03 03:01:55 AM |   (0/196):Loss 0.0478 Prec@1(1,5) 99.61, 100.00
11/03 03:02:01 AM |   (50/196):Loss 0.0755 Prec@1(1,5) 97.79, 99.99
11/03 03:02:06 AM |   (100/196):Loss 0.0734 Prec@1(1,5) 97.83, 99.98
11/03 03:02:12 AM |   (150/196):Loss 0.0762 Prec@1(1,5) 97.67, 99.99
11/03 03:02:19 AM |  * Acc@1 90.070 Acc@5 99.590
11/03 03:02:19 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:02:19 AM | ----
11/03 03:02:19 AM | Epoch[6]
11/03 03:02:19 AM | learning_rate: 0.019955619646030796
11/03 03:02:20 AM |   (0/196):Loss 0.0614 Prec@1(1,5) 98.83, 100.00
11/03 03:02:25 AM |   (50/196):Loss 0.0859 Prec@1(1,5) 97.23, 100.00
11/03 03:02:31 AM |   (100/196):Loss 0.0867 Prec@1(1,5) 97.22, 100.00
11/03 03:02:36 AM |   (150/196):Loss 0.0917 Prec@1(1,5) 97.09, 100.00
11/03 03:02:43 AM |  * Acc@1 89.240 Acc@5 99.690
11/03 03:02:43 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:02:43 AM | ----
11/03 03:02:43 AM | Epoch[7]
11/03 03:02:43 AM | learning_rate: 0.019939609554551794
11/03 03:02:44 AM |   (0/196):Loss 0.0876 Prec@1(1,5) 98.44, 100.00
11/03 03:02:50 AM |   (50/196):Loss 0.1019 Prec@1(1,5) 96.83, 99.98
11/03 03:02:55 AM |   (100/196):Loss 0.1011 Prec@1(1,5) 96.81, 99.98
11/03 03:03:01 AM |   (150/196):Loss 0.1045 Prec@1(1,5) 96.66, 99.97
11/03 03:03:08 AM |  * Acc@1 87.650 Acc@5 99.460
11/03 03:03:08 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:03:08 AM | ----
11/03 03:03:08 AM | Epoch[8]
11/03 03:03:08 AM | learning_rate: 0.019921147013144774
11/03 03:03:09 AM |   (0/196):Loss 0.0903 Prec@1(1,5) 96.88, 100.00
11/03 03:03:14 AM |   (50/196):Loss 0.1318 Prec@1(1,5) 95.72, 99.98
11/03 03:03:20 AM |   (100/196):Loss 0.1286 Prec@1(1,5) 95.81, 99.98
11/03 03:03:25 AM |   (150/196):Loss 0.1308 Prec@1(1,5) 95.73, 99.97
11/03 03:03:32 AM |  * Acc@1 87.810 Acc@5 99.450
11/03 03:03:32 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:03:32 AM | ----
11/03 03:03:32 AM | Epoch[9]
11/03 03:03:32 AM | learning_rate: 0.019900236577165567
11/03 03:03:33 AM |   (0/196):Loss 0.1100 Prec@1(1,5) 97.66, 100.00
11/03 03:03:38 AM |   (50/196):Loss 0.1238 Prec@1(1,5) 95.87, 99.97
11/03 03:03:44 AM |   (100/196):Loss 0.1298 Prec@1(1,5) 95.70, 99.94
11/03 03:03:50 AM |   (150/196):Loss 0.1363 Prec@1(1,5) 95.42, 99.94
11/03 03:03:57 AM |  * Acc@1 88.060 Acc@5 99.610
11/03 03:03:57 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:03:57 AM | ----
11/03 03:03:57 AM | Epoch[10]
11/03 03:03:57 AM | learning_rate: 0.019876883405951368
11/03 03:03:57 AM |   (0/196):Loss 0.1318 Prec@1(1,5) 94.92, 100.00
11/03 03:04:03 AM |   (50/196):Loss 0.1548 Prec@1(1,5) 94.91, 99.96
11/03 03:04:09 AM |   (100/196):Loss 0.1555 Prec@1(1,5) 94.99, 99.96
11/03 03:04:14 AM |   (150/196):Loss 0.1593 Prec@1(1,5) 94.80, 99.96
11/03 03:04:21 AM |  * Acc@1 87.470 Acc@5 99.580
11/03 03:04:21 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:04:21 AM | ----
11/03 03:04:21 AM | Epoch[11]
11/03 03:04:21 AM | learning_rate: 0.019851093261547728
11/03 03:04:22 AM |   (0/196):Loss 0.1284 Prec@1(1,5) 96.48, 100.00
11/03 03:04:27 AM |   (50/196):Loss 0.1637 Prec@1(1,5) 94.36, 99.95
11/03 03:04:33 AM |   (100/196):Loss 0.1635 Prec@1(1,5) 94.41, 99.96
11/03 03:04:38 AM |   (150/196):Loss 0.1676 Prec@1(1,5) 94.34, 99.95
11/03 03:04:45 AM |  * Acc@1 83.240 Acc@5 98.960
11/03 03:04:45 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:04:45 AM | ----
11/03 03:04:45 AM | Epoch[12]
11/03 03:04:45 AM | learning_rate: 0.019822872507286877
11/03 03:04:46 AM |   (0/196):Loss 0.1536 Prec@1(1,5) 93.75, 100.00
11/03 03:04:51 AM |   (50/196):Loss 0.1802 Prec@1(1,5) 93.89, 99.90
11/03 03:04:57 AM |   (100/196):Loss 0.1750 Prec@1(1,5) 94.04, 99.93
11/03 03:05:02 AM |   (150/196):Loss 0.1797 Prec@1(1,5) 93.92, 99.90
11/03 03:05:09 AM |  * Acc@1 86.220 Acc@5 99.540
11/03 03:05:09 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:05:09 AM | ----
11/03 03:05:09 AM | Epoch[13]
11/03 03:05:09 AM | learning_rate: 0.019792228106217648
11/03 03:05:10 AM |   (0/196):Loss 0.1163 Prec@1(1,5) 96.09, 100.00
11/03 03:05:15 AM |   (50/196):Loss 0.1847 Prec@1(1,5) 93.86, 99.89
11/03 03:05:21 AM |   (100/196):Loss 0.1876 Prec@1(1,5) 93.74, 99.90
11/03 03:05:27 AM |   (150/196):Loss 0.1960 Prec@1(1,5) 93.46, 99.88
11/03 03:05:34 AM |  * Acc@1 85.710 Acc@5 99.180
11/03 03:05:34 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:05:34 AM | ----
11/03 03:05:34 AM | Epoch[14]
11/03 03:05:34 AM | learning_rate: 0.019759167619387466
11/03 03:05:35 AM |   (0/196):Loss 0.1953 Prec@1(1,5) 92.97, 100.00
11/03 03:05:40 AM |   (50/196):Loss 0.2008 Prec@1(1,5) 93.11, 99.92
11/03 03:05:46 AM |   (100/196):Loss 0.1956 Prec@1(1,5) 93.36, 99.90
11/03 03:05:51 AM |   (150/196):Loss 0.1967 Prec@1(1,5) 93.32, 99.92
11/03 03:05:58 AM |  * Acc@1 86.350 Acc@5 99.370
11/03 03:05:58 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:05:58 AM | ----
11/03 03:05:58 AM | Epoch[15]
11/03 03:05:58 AM | learning_rate: 0.019723699203976756
11/03 03:05:59 AM |   (0/196):Loss 0.1968 Prec@1(1,5) 93.36, 99.22
11/03 03:06:05 AM |   (50/196):Loss 0.2087 Prec@1(1,5) 92.95, 99.91
11/03 03:06:10 AM |   (100/196):Loss 0.2059 Prec@1(1,5) 93.11, 99.90
11/03 03:06:16 AM |   (150/196):Loss 0.2106 Prec@1(1,5) 92.94, 99.88
11/03 03:06:23 AM |  * Acc@1 85.520 Acc@5 99.340
11/03 03:06:23 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:06:23 AM | ----
11/03 03:06:23 AM | Epoch[16]
11/03 03:06:23 AM | learning_rate: 0.0196858316112863
11/03 03:06:23 AM |   (0/196):Loss 0.1724 Prec@1(1,5) 94.53, 99.61
11/03 03:06:29 AM |   (50/196):Loss 0.2099 Prec@1(1,5) 93.04, 99.85
11/03 03:06:34 AM |   (100/196):Loss 0.2119 Prec@1(1,5) 92.97, 99.87
11/03 03:06:40 AM |   (150/196):Loss 0.2186 Prec@1(1,5) 92.73, 99.87
11/03 03:06:47 AM |  * Acc@1 83.110 Acc@5 99.070
11/03 03:06:47 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:06:47 AM | ----
11/03 03:06:47 AM | Epoch[17]
11/03 03:06:47 AM | learning_rate: 0.01964557418457797
11/03 03:06:47 AM |   (0/196):Loss 0.1720 Prec@1(1,5) 94.14, 100.00
11/03 03:06:53 AM |   (50/196):Loss 0.2013 Prec@1(1,5) 93.27, 99.89
11/03 03:06:59 AM |   (100/196):Loss 0.2160 Prec@1(1,5) 92.76, 99.85
11/03 03:07:04 AM |   (150/196):Loss 0.2209 Prec@1(1,5) 92.53, 99.87
11/03 03:07:11 AM |  * Acc@1 82.760 Acc@5 98.730
11/03 03:07:11 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:07:11 AM | ----
11/03 03:07:11 AM | Epoch[18]
11/03 03:07:11 AM | learning_rate: 0.01960293685676942
11/03 03:07:11 AM |   (0/196):Loss 0.2045 Prec@1(1,5) 93.36, 100.00
11/03 03:07:17 AM |   (50/196):Loss 0.2155 Prec@1(1,5) 92.83, 99.83
11/03 03:07:23 AM |   (100/196):Loss 0.2233 Prec@1(1,5) 92.47, 99.84
11/03 03:07:28 AM |   (150/196):Loss 0.2277 Prec@1(1,5) 92.32, 99.81
11/03 03:07:35 AM |  * Acc@1 84.840 Acc@5 99.430
11/03 03:07:35 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:07:35 AM | ----
11/03 03:07:35 AM | Epoch[19]
11/03 03:07:35 AM | learning_rate: 0.01955793014798329
11/03 03:07:36 AM |   (0/196):Loss 0.1593 Prec@1(1,5) 94.92, 100.00
11/03 03:07:42 AM |   (50/196):Loss 0.2319 Prec@1(1,5) 92.15, 99.82
11/03 03:07:47 AM |   (100/196):Loss 0.2263 Prec@1(1,5) 92.42, 99.84
11/03 03:07:53 AM |   (150/196):Loss 0.2297 Prec@1(1,5) 92.22, 99.83
11/03 03:08:00 AM |  * Acc@1 79.760 Acc@5 98.570
11/03 03:08:00 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:08:00 AM | ----
11/03 03:08:00 AM | Epoch[20]
11/03 03:08:00 AM | learning_rate: 0.019510565162951524
11/03 03:08:00 AM |   (0/196):Loss 0.2377 Prec@1(1,5) 92.19, 100.00
11/03 03:08:06 AM |   (50/196):Loss 0.2222 Prec@1(1,5) 92.48, 99.79
11/03 03:08:12 AM |   (100/196):Loss 0.2243 Prec@1(1,5) 92.35, 99.82
11/03 03:08:17 AM |   (150/196):Loss 0.2297 Prec@1(1,5) 92.23, 99.83
11/03 03:08:24 AM |  * Acc@1 86.240 Acc@5 99.250
11/03 03:08:24 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:08:24 AM | ----
11/03 03:08:24 AM | Epoch[21]
11/03 03:08:24 AM | learning_rate: 0.01946085358827544
11/03 03:08:24 AM |   (0/196):Loss 0.2730 Prec@1(1,5) 91.02, 100.00
11/03 03:08:30 AM |   (50/196):Loss 0.2290 Prec@1(1,5) 92.61, 99.85
11/03 03:08:36 AM |   (100/196):Loss 0.2298 Prec@1(1,5) 92.43, 99.85
11/03 03:08:41 AM |   (150/196):Loss 0.2336 Prec@1(1,5) 92.23, 99.84
11/03 03:08:48 AM |  * Acc@1 81.980 Acc@5 99.010
11/03 03:08:48 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:08:48 AM | ----
11/03 03:08:48 AM | Epoch[22]
11/03 03:08:48 AM | learning_rate: 0.01940880768954224
11/03 03:08:49 AM |   (0/196):Loss 0.2811 Prec@1(1,5) 89.45, 100.00
11/03 03:08:54 AM |   (50/196):Loss 0.2328 Prec@1(1,5) 91.96, 99.82
11/03 03:09:00 AM |   (100/196):Loss 0.2336 Prec@1(1,5) 91.85, 99.83
11/03 03:09:05 AM |   (150/196):Loss 0.2310 Prec@1(1,5) 92.01, 99.83
11/03 03:09:12 AM |  * Acc@1 84.260 Acc@5 99.320
11/03 03:09:12 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:09:12 AM | ----
11/03 03:09:12 AM | Epoch[23]
11/03 03:09:12 AM | learning_rate: 0.01935444030829866
11/03 03:09:13 AM |   (0/196):Loss 0.2624 Prec@1(1,5) 90.62, 99.61
11/03 03:09:19 AM |   (50/196):Loss 0.2392 Prec@1(1,5) 92.03, 99.79
11/03 03:09:24 AM |   (100/196):Loss 0.2394 Prec@1(1,5) 92.01, 99.81
11/03 03:09:30 AM |   (150/196):Loss 0.2448 Prec@1(1,5) 91.83, 99.83
11/03 03:09:37 AM |  * Acc@1 82.740 Acc@5 98.920
11/03 03:09:37 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:09:37 AM | ----
11/03 03:09:37 AM | Epoch[24]
11/03 03:09:37 AM | learning_rate: 0.0192977648588825
11/03 03:09:37 AM |   (0/196):Loss 0.1826 Prec@1(1,5) 93.36, 99.61
11/03 03:09:43 AM |   (50/196):Loss 0.2224 Prec@1(1,5) 92.64, 99.87
11/03 03:09:49 AM |   (100/196):Loss 0.2300 Prec@1(1,5) 92.42, 99.86
11/03 03:09:54 AM |   (150/196):Loss 0.2322 Prec@1(1,5) 92.24, 99.88
11/03 03:10:01 AM |  * Acc@1 85.550 Acc@5 99.490
11/03 03:10:01 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:10:01 AM | ----
11/03 03:10:01 AM | Epoch[25]
11/03 03:10:01 AM | learning_rate: 0.019238795325112853
11/03 03:10:02 AM |   (0/196):Loss 0.1984 Prec@1(1,5) 92.97, 100.00
11/03 03:10:07 AM |   (50/196):Loss 0.2267 Prec@1(1,5) 92.40, 99.89
11/03 03:10:13 AM |   (100/196):Loss 0.2289 Prec@1(1,5) 92.25, 99.88
11/03 03:10:19 AM |   (150/196):Loss 0.2342 Prec@1(1,5) 92.05, 99.85
11/03 03:10:25 AM |  * Acc@1 85.060 Acc@5 99.310
11/03 03:10:25 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:10:25 AM | ----
11/03 03:10:25 AM | Epoch[26]
11/03 03:10:25 AM | learning_rate: 0.019177546256839796
11/03 03:10:26 AM |   (0/196):Loss 0.2553 Prec@1(1,5) 89.84, 100.00
11/03 03:10:32 AM |   (50/196):Loss 0.2351 Prec@1(1,5) 92.08, 99.82
11/03 03:10:37 AM |   (100/196):Loss 0.2409 Prec@1(1,5) 91.91, 99.83
11/03 03:10:43 AM |   (150/196):Loss 0.2394 Prec@1(1,5) 91.90, 99.82
11/03 03:10:50 AM |  * Acc@1 78.330 Acc@5 98.200
11/03 03:10:50 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:10:50 AM | ----
11/03 03:10:50 AM | Epoch[27]
11/03 03:10:50 AM | learning_rate: 0.019114032766354438
11/03 03:10:50 AM |   (0/196):Loss 0.2250 Prec@1(1,5) 92.19, 100.00
11/03 03:10:56 AM |   (50/196):Loss 0.2320 Prec@1(1,5) 92.29, 99.89
11/03 03:11:02 AM |   (100/196):Loss 0.2388 Prec@1(1,5) 91.95, 99.82
11/03 03:11:07 AM |   (150/196):Loss 0.2435 Prec@1(1,5) 91.91, 99.83
11/03 03:11:14 AM |  * Acc@1 83.420 Acc@5 98.790
11/03 03:11:14 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:11:14 AM | ----
11/03 03:11:14 AM | Epoch[28]
11/03 03:11:14 AM | learning_rate: 0.019048270524660182
11/03 03:11:15 AM |   (0/196):Loss 0.1896 Prec@1(1,5) 92.58, 99.61
11/03 03:11:20 AM |   (50/196):Loss 0.2208 Prec@1(1,5) 92.67, 99.85
11/03 03:11:26 AM |   (100/196):Loss 0.2338 Prec@1(1,5) 92.24, 99.86
11/03 03:11:31 AM |   (150/196):Loss 0.2324 Prec@1(1,5) 92.22, 99.84
11/03 03:11:38 AM |  * Acc@1 80.740 Acc@5 99.170
11/03 03:11:38 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:11:38 AM | ----
11/03 03:11:38 AM | Epoch[29]
11/03 03:11:38 AM | learning_rate: 0.018980275757606142
11/03 03:11:39 AM |   (0/196):Loss 0.2001 Prec@1(1,5) 94.14, 100.00
11/03 03:11:45 AM |   (50/196):Loss 0.2397 Prec@1(1,5) 91.97, 99.80
11/03 03:11:50 AM |   (100/196):Loss 0.2327 Prec@1(1,5) 92.16, 99.85
11/03 03:11:56 AM |   (150/196):Loss 0.2396 Prec@1(1,5) 91.96, 99.85
11/03 03:12:03 AM |  * Acc@1 78.480 Acc@5 98.270
11/03 03:12:03 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:12:03 AM | ----
11/03 03:12:03 AM | Epoch[30]
11/03 03:12:03 AM | learning_rate: 0.018910065241883666
11/03 03:12:03 AM |   (0/196):Loss 0.1659 Prec@1(1,5) 95.31, 99.61
11/03 03:12:09 AM |   (50/196):Loss 0.2410 Prec@1(1,5) 91.80, 99.79
11/03 03:12:15 AM |   (100/196):Loss 0.2403 Prec@1(1,5) 91.81, 99.81
11/03 03:12:20 AM |   (150/196):Loss 0.2356 Prec@1(1,5) 92.01, 99.80
11/03 03:12:27 AM |  * Acc@1 79.190 Acc@5 98.090
11/03 03:12:27 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:12:27 AM | ----
11/03 03:12:27 AM | Epoch[31]
11/03 03:12:27 AM | learning_rate: 0.018837656300886924
11/03 03:12:28 AM |   (0/196):Loss 0.2080 Prec@1(1,5) 92.97, 100.00
11/03 03:12:33 AM |   (50/196):Loss 0.2307 Prec@1(1,5) 92.25, 99.85
11/03 03:12:39 AM |   (100/196):Loss 0.2353 Prec@1(1,5) 92.05, 99.85
11/03 03:12:44 AM |   (150/196):Loss 0.2350 Prec@1(1,5) 92.14, 99.83
11/03 03:12:51 AM |  * Acc@1 83.460 Acc@5 98.930
11/03 03:12:51 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:12:51 AM | ----
11/03 03:12:51 AM | Epoch[32]
11/03 03:12:51 AM | learning_rate: 0.018763066800438623
11/03 03:12:52 AM |   (0/196):Loss 0.1526 Prec@1(1,5) 94.92, 100.00
11/03 03:12:58 AM |   (50/196):Loss 0.2085 Prec@1(1,5) 92.98, 99.84
11/03 03:13:03 AM |   (100/196):Loss 0.2232 Prec@1(1,5) 92.58, 99.85
11/03 03:13:09 AM |   (150/196):Loss 0.2270 Prec@1(1,5) 92.42, 99.83
11/03 03:13:16 AM |  * Acc@1 86.750 Acc@5 99.590
11/03 03:13:16 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:13:16 AM | ----
11/03 03:13:16 AM | Epoch[33]
11/03 03:13:16 AM | learning_rate: 0.0186863151443819
11/03 03:13:16 AM |   (0/196):Loss 0.2481 Prec@1(1,5) 89.84, 99.61
11/03 03:13:22 AM |   (50/196):Loss 0.2413 Prec@1(1,5) 91.93, 99.81
11/03 03:13:28 AM |   (100/196):Loss 0.2351 Prec@1(1,5) 92.19, 99.83
11/03 03:13:33 AM |   (150/196):Loss 0.2373 Prec@1(1,5) 92.04, 99.82
11/03 03:13:40 AM |  * Acc@1 80.670 Acc@5 99.240
11/03 03:13:40 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:13:40 AM | ----
11/03 03:13:40 AM | Epoch[34]
11/03 03:13:40 AM | learning_rate: 0.018607420270039424
11/03 03:13:40 AM |   (0/196):Loss 0.1986 Prec@1(1,5) 92.97, 100.00
11/03 03:13:46 AM |   (50/196):Loss 0.2204 Prec@1(1,5) 92.77, 99.84
11/03 03:13:52 AM |   (100/196):Loss 0.2245 Prec@1(1,5) 92.59, 99.85
11/03 03:13:57 AM |   (150/196):Loss 0.2317 Prec@1(1,5) 92.25, 99.82
11/03 03:14:04 AM |  * Acc@1 82.220 Acc@5 98.670
11/03 03:14:04 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:14:04 AM | ----
11/03 03:14:04 AM | Epoch[35]
11/03 03:14:04 AM | learning_rate: 0.01852640164354091
11/03 03:14:05 AM |   (0/196):Loss 0.2473 Prec@1(1,5) 91.41, 100.00
11/03 03:14:10 AM |   (50/196):Loss 0.2358 Prec@1(1,5) 92.22, 99.80
11/03 03:14:16 AM |   (100/196):Loss 0.2320 Prec@1(1,5) 92.31, 99.84
11/03 03:14:22 AM |   (150/196):Loss 0.2337 Prec@1(1,5) 92.15, 99.83
11/03 03:14:28 AM |  * Acc@1 83.780 Acc@5 99.310
11/03 03:14:28 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:14:28 AM | ----
11/03 03:14:28 AM | Epoch[36]
11/03 03:14:28 AM | learning_rate: 0.018443279255020137
11/03 03:14:29 AM |   (0/196):Loss 0.2224 Prec@1(1,5) 93.75, 100.00
11/03 03:14:34 AM |   (50/196):Loss 0.2446 Prec@1(1,5) 91.66, 99.85
11/03 03:14:40 AM |   (100/196):Loss 0.2371 Prec@1(1,5) 91.89, 99.85
11/03 03:14:46 AM |   (150/196):Loss 0.2402 Prec@1(1,5) 91.84, 99.81
11/03 03:14:53 AM |  * Acc@1 86.630 Acc@5 99.420
11/03 03:14:53 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:14:53 AM | ----
11/03 03:14:53 AM | Epoch[37]
11/03 03:14:53 AM | learning_rate: 0.01835807361368269
11/03 03:14:53 AM |   (0/196):Loss 0.2128 Prec@1(1,5) 91.80, 99.61
11/03 03:14:59 AM |   (50/196):Loss 0.2338 Prec@1(1,5) 92.41, 99.84
11/03 03:15:04 AM |   (100/196):Loss 0.2313 Prec@1(1,5) 92.38, 99.82
11/03 03:15:10 AM |   (150/196):Loss 0.2386 Prec@1(1,5) 92.08, 99.83
11/03 03:15:17 AM |  * Acc@1 81.810 Acc@5 99.090
11/03 03:15:17 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:15:17 AM | ----
11/03 03:15:17 AM | Epoch[38]
11/03 03:15:17 AM | learning_rate: 0.018270805742745602
11/03 03:15:17 AM |   (0/196):Loss 0.1522 Prec@1(1,5) 94.53, 100.00
11/03 03:15:23 AM |   (50/196):Loss 0.2376 Prec@1(1,5) 92.08, 99.84
11/03 03:15:29 AM |   (100/196):Loss 0.2304 Prec@1(1,5) 92.37, 99.85
11/03 03:15:34 AM |   (150/196):Loss 0.2322 Prec@1(1,5) 92.38, 99.83
11/03 03:15:41 AM |  * Acc@1 82.720 Acc@5 99.100
11/03 03:15:41 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:15:41 AM | ----
11/03 03:15:41 AM | Epoch[39]
11/03 03:15:41 AM | learning_rate: 0.01818149717425022
11/03 03:15:42 AM |   (0/196):Loss 0.1930 Prec@1(1,5) 93.36, 100.00
11/03 03:15:48 AM |   (50/196):Loss 0.2413 Prec@1(1,5) 91.99, 99.79
11/03 03:15:53 AM |   (100/196):Loss 0.2436 Prec@1(1,5) 91.84, 99.82
11/03 03:15:59 AM |   (150/196):Loss 0.2413 Prec@1(1,5) 91.83, 99.84
11/03 03:16:05 AM |  * Acc@1 84.810 Acc@5 99.230
11/03 03:16:06 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:16:06 AM | ----
11/03 03:16:06 AM | Epoch[40]
11/03 03:16:06 AM | learning_rate: 0.01809016994374946
11/03 03:16:06 AM |   (0/196):Loss 0.2456 Prec@1(1,5) 90.23, 100.00
11/03 03:16:12 AM |   (50/196):Loss 0.2214 Prec@1(1,5) 92.47, 99.89
11/03 03:16:17 AM |   (100/196):Loss 0.2268 Prec@1(1,5) 92.47, 99.85
11/03 03:16:23 AM |   (150/196):Loss 0.2281 Prec@1(1,5) 92.42, 99.87
11/03 03:16:30 AM |  * Acc@1 85.350 Acc@5 99.090
11/03 03:16:30 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:16:30 AM | ----
11/03 03:16:30 AM | Epoch[41]
11/03 03:16:30 AM | learning_rate: 0.01799684658487089
11/03 03:16:30 AM |   (0/196):Loss 0.2684 Prec@1(1,5) 90.62, 100.00
11/03 03:16:36 AM |   (50/196):Loss 0.2408 Prec@1(1,5) 91.93, 99.85
11/03 03:16:42 AM |   (100/196):Loss 0.2363 Prec@1(1,5) 92.01, 99.86
11/03 03:16:47 AM |   (150/196):Loss 0.2396 Prec@1(1,5) 91.93, 99.84
11/03 03:16:54 AM |  * Acc@1 79.960 Acc@5 98.890
11/03 03:16:54 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:16:54 AM | ----
11/03 03:16:54 AM | Epoch[42]
11/03 03:16:54 AM | learning_rate: 0.017901550123756885
11/03 03:16:55 AM |   (0/196):Loss 0.1493 Prec@1(1,5) 94.92, 100.00
11/03 03:17:01 AM |   (50/196):Loss 0.2125 Prec@1(1,5) 92.96, 99.78
11/03 03:17:06 AM |   (100/196):Loss 0.2200 Prec@1(1,5) 92.73, 99.80
11/03 03:17:12 AM |   (150/196):Loss 0.2280 Prec@1(1,5) 92.45, 99.81
11/03 03:17:19 AM |  * Acc@1 87.120 Acc@5 99.370
11/03 03:17:19 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:17:19 AM | ----
11/03 03:17:19 AM | Epoch[43]
11/03 03:17:19 AM | learning_rate: 0.017804304073383282
11/03 03:17:19 AM |   (0/196):Loss 0.1941 Prec@1(1,5) 93.36, 100.00
11/03 03:17:25 AM |   (50/196):Loss 0.2131 Prec@1(1,5) 92.88, 99.91
11/03 03:17:31 AM |   (100/196):Loss 0.2239 Prec@1(1,5) 92.49, 99.87
11/03 03:17:36 AM |   (150/196):Loss 0.2263 Prec@1(1,5) 92.44, 99.86
11/03 03:17:43 AM |  * Acc@1 83.520 Acc@5 99.200
11/03 03:17:43 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:17:43 AM | ----
11/03 03:17:43 AM | Epoch[44]
11/03 03:17:43 AM | learning_rate: 0.017705132427757876
11/03 03:17:44 AM |   (0/196):Loss 0.2194 Prec@1(1,5) 93.75, 99.22
11/03 03:17:49 AM |   (50/196):Loss 0.2172 Prec@1(1,5) 92.64, 99.83
11/03 03:17:55 AM |   (100/196):Loss 0.2216 Prec@1(1,5) 92.50, 99.82
11/03 03:18:01 AM |   (150/196):Loss 0.2282 Prec@1(1,5) 92.33, 99.82
11/03 03:18:08 AM |  * Acc@1 83.640 Acc@5 99.230
11/03 03:18:08 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:18:08 AM | ----
11/03 03:18:08 AM | Epoch[45]
11/03 03:18:08 AM | learning_rate: 0.017604059656000294
11/03 03:18:08 AM |   (0/196):Loss 0.2592 Prec@1(1,5) 89.84, 100.00
11/03 03:18:14 AM |   (50/196):Loss 0.2184 Prec@1(1,5) 92.72, 99.86
11/03 03:18:20 AM |   (100/196):Loss 0.2232 Prec@1(1,5) 92.50, 99.85
11/03 03:18:25 AM |   (150/196):Loss 0.2288 Prec@1(1,5) 92.29, 99.85
11/03 03:18:32 AM |  * Acc@1 86.520 Acc@5 99.220
11/03 03:18:32 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:18:32 AM | ----
11/03 03:18:32 AM | Epoch[46]
11/03 03:18:32 AM | learning_rate: 0.01750111069630458
11/03 03:18:33 AM |   (0/196):Loss 0.1823 Prec@1(1,5) 93.36, 100.00
11/03 03:18:38 AM |   (50/196):Loss 0.2193 Prec@1(1,5) 92.77, 99.91
11/03 03:18:44 AM |   (100/196):Loss 0.2159 Prec@1(1,5) 92.83, 99.86
11/03 03:18:49 AM |   (150/196):Loss 0.2239 Prec@1(1,5) 92.47, 99.87
11/03 03:18:56 AM |  * Acc@1 84.480 Acc@5 99.380
11/03 03:18:56 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:18:56 AM | ----
11/03 03:18:56 AM | Epoch[47]
11/03 03:18:56 AM | learning_rate: 0.017396310949786078
11/03 03:18:57 AM |   (0/196):Loss 0.2103 Prec@1(1,5) 94.14, 99.61
11/03 03:19:03 AM |   (50/196):Loss 0.2335 Prec@1(1,5) 92.11, 99.78
11/03 03:19:08 AM |   (100/196):Loss 0.2241 Prec@1(1,5) 92.60, 99.77
11/03 03:19:14 AM |   (150/196):Loss 0.2280 Prec@1(1,5) 92.47, 99.79
11/03 03:19:21 AM |  * Acc@1 79.750 Acc@5 99.010
11/03 03:19:21 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:19:21 AM | ----
11/03 03:19:21 AM | Epoch[48]
11/03 03:19:21 AM | learning_rate: 0.017289686274214098
11/03 03:19:22 AM |   (0/196):Loss 0.1571 Prec@1(1,5) 95.31, 100.00
11/03 03:19:27 AM |   (50/196):Loss 0.2094 Prec@1(1,5) 92.78, 99.85
11/03 03:19:33 AM |   (100/196):Loss 0.2250 Prec@1(1,5) 92.36, 99.85
11/03 03:19:39 AM |   (150/196):Loss 0.2286 Prec@1(1,5) 92.27, 99.84
11/03 03:19:45 AM |  * Acc@1 82.170 Acc@5 98.350
11/03 03:19:46 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:19:46 AM | ----
11/03 03:19:46 AM | Epoch[49]
11/03 03:19:46 AM | learning_rate: 0.01718126297763187
11/03 03:19:46 AM |   (0/196):Loss 0.2894 Prec@1(1,5) 90.23, 99.61
11/03 03:19:52 AM |   (50/196):Loss 0.2210 Prec@1(1,5) 92.65, 99.79
11/03 03:19:58 AM |   (100/196):Loss 0.2223 Prec@1(1,5) 92.58, 99.81
11/03 03:20:03 AM |   (150/196):Loss 0.2267 Prec@1(1,5) 92.44, 99.82
11/03 03:20:10 AM |  * Acc@1 87.210 Acc@5 99.490
11/03 03:20:10 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:20:10 AM | ----
11/03 03:20:10 AM | Epoch[50]
11/03 03:20:10 AM | learning_rate: 0.017071067811865456
11/03 03:20:11 AM |   (0/196):Loss 0.2420 Prec@1(1,5) 91.80, 99.61
11/03 03:20:16 AM |   (50/196):Loss 0.2239 Prec@1(1,5) 92.33, 99.90
11/03 03:20:22 AM |   (100/196):Loss 0.2208 Prec@1(1,5) 92.50, 99.89
11/03 03:20:28 AM |   (150/196):Loss 0.2241 Prec@1(1,5) 92.44, 99.86
11/03 03:20:34 AM |  * Acc@1 78.880 Acc@5 99.180
11/03 03:20:34 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:20:34 AM | ----
11/03 03:20:34 AM | Epoch[51]
11/03 03:20:34 AM | learning_rate: 0.016959127965923124
11/03 03:20:35 AM |   (0/196):Loss 0.2313 Prec@1(1,5) 92.19, 100.00
11/03 03:20:41 AM |   (50/196):Loss 0.2140 Prec@1(1,5) 92.95, 99.84
11/03 03:20:46 AM |   (100/196):Loss 0.2206 Prec@1(1,5) 92.64, 99.83
11/03 03:20:52 AM |   (150/196):Loss 0.2210 Prec@1(1,5) 92.55, 99.85
11/03 03:20:59 AM |  * Acc@1 84.970 Acc@5 99.120
11/03 03:20:59 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:20:59 AM | ----
11/03 03:20:59 AM | Epoch[52]
11/03 03:20:59 AM | learning_rate: 0.016845471059286868
11/03 03:21:00 AM |   (0/196):Loss 0.1855 Prec@1(1,5) 95.31, 99.61
11/03 03:21:05 AM |   (50/196):Loss 0.2133 Prec@1(1,5) 92.72, 99.87
11/03 03:21:11 AM |   (100/196):Loss 0.2127 Prec@1(1,5) 92.76, 99.87
11/03 03:21:16 AM |   (150/196):Loss 0.2212 Prec@1(1,5) 92.45, 99.86
11/03 03:21:23 AM |  * Acc@1 86.330 Acc@5 99.280
11/03 03:21:23 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:21:23 AM | ----
11/03 03:21:23 AM | Epoch[53]
11/03 03:21:23 AM | learning_rate: 0.016730125135097713
11/03 03:21:24 AM |   (0/196):Loss 0.2083 Prec@1(1,5) 91.02, 100.00
11/03 03:21:30 AM |   (50/196):Loss 0.2149 Prec@1(1,5) 92.77, 99.84
11/03 03:21:35 AM |   (100/196):Loss 0.2135 Prec@1(1,5) 92.83, 99.85
11/03 03:21:41 AM |   (150/196):Loss 0.2169 Prec@1(1,5) 92.67, 99.87
11/03 03:21:47 AM |  * Acc@1 80.550 Acc@5 99.080
11/03 03:21:48 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:21:48 AM | ----
11/03 03:21:48 AM | Epoch[54]
11/03 03:21:48 AM | learning_rate: 0.0166131186532365
11/03 03:21:48 AM |   (0/196):Loss 0.2111 Prec@1(1,5) 92.19, 100.00
11/03 03:21:54 AM |   (50/196):Loss 0.2000 Prec@1(1,5) 93.43, 99.88
11/03 03:22:00 AM |   (100/196):Loss 0.2109 Prec@1(1,5) 92.97, 99.85
11/03 03:22:05 AM |   (150/196):Loss 0.2211 Prec@1(1,5) 92.69, 99.81
11/03 03:22:12 AM |  * Acc@1 87.700 Acc@5 99.450
11/03 03:22:12 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:22:12 AM | ----
11/03 03:22:12 AM | Epoch[55]
11/03 03:22:12 AM | learning_rate: 0.016494480483301818
11/03 03:22:13 AM |   (0/196):Loss 0.1238 Prec@1(1,5) 95.31, 100.00
11/03 03:22:18 AM |   (50/196):Loss 0.2122 Prec@1(1,5) 92.66, 99.90
11/03 03:22:24 AM |   (100/196):Loss 0.2218 Prec@1(1,5) 92.42, 99.86
11/03 03:22:30 AM |   (150/196):Loss 0.2214 Prec@1(1,5) 92.46, 99.85
11/03 03:22:36 AM |  * Acc@1 84.110 Acc@5 99.470
11/03 03:22:36 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:22:36 AM | ----
11/03 03:22:36 AM | Epoch[56]
11/03 03:22:36 AM | learning_rate: 0.01637423989748688
11/03 03:22:37 AM |   (0/196):Loss 0.2392 Prec@1(1,5) 91.02, 100.00
11/03 03:22:43 AM |   (50/196):Loss 0.2275 Prec@1(1,5) 92.23, 99.82
11/03 03:22:48 AM |   (100/196):Loss 0.2233 Prec@1(1,5) 92.43, 99.83
11/03 03:22:54 AM |   (150/196):Loss 0.2193 Prec@1(1,5) 92.59, 99.86
11/03 03:23:01 AM |  * Acc@1 84.350 Acc@5 99.220
11/03 03:23:01 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:23:01 AM | ----
11/03 03:23:01 AM | Epoch[57]
11/03 03:23:01 AM | learning_rate: 0.016252426563357035
11/03 03:23:02 AM |   (0/196):Loss 0.1814 Prec@1(1,5) 93.36, 100.00
11/03 03:23:07 AM |   (50/196):Loss 0.1959 Prec@1(1,5) 93.35, 99.88
11/03 03:23:13 AM |   (100/196):Loss 0.2026 Prec@1(1,5) 93.14, 99.90
11/03 03:23:18 AM |   (150/196):Loss 0.2094 Prec@1(1,5) 92.93, 99.88
11/03 03:23:25 AM |  * Acc@1 85.820 Acc@5 99.070
11/03 03:23:25 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:23:25 AM | ----
11/03 03:23:25 AM | Epoch[58]
11/03 03:23:25 AM | learning_rate: 0.016129070536529747
11/03 03:23:26 AM |   (0/196):Loss 0.1783 Prec@1(1,5) 94.92, 100.00
11/03 03:23:31 AM |   (50/196):Loss 0.2107 Prec@1(1,5) 93.01, 99.87
11/03 03:23:37 AM |   (100/196):Loss 0.2080 Prec@1(1,5) 92.99, 99.88
11/03 03:23:43 AM |   (150/196):Loss 0.2107 Prec@1(1,5) 92.92, 99.87
11/03 03:23:49 AM |  * Acc@1 87.450 Acc@5 99.310
11/03 03:23:49 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:23:49 AM | ----
11/03 03:23:49 AM | Epoch[59]
11/03 03:23:49 AM | learning_rate: 0.016004202253258822
11/03 03:23:50 AM |   (0/196):Loss 0.1986 Prec@1(1,5) 92.97, 100.00
11/03 03:23:56 AM |   (50/196):Loss 0.1949 Prec@1(1,5) 93.49, 99.92
11/03 03:24:02 AM |   (100/196):Loss 0.2000 Prec@1(1,5) 93.31, 99.91
11/03 03:24:07 AM |   (150/196):Loss 0.2052 Prec@1(1,5) 93.15, 99.88
11/03 03:24:14 AM |  * Acc@1 85.280 Acc@5 99.370
11/03 03:24:14 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:24:14 AM | ----
11/03 03:24:14 AM | Epoch[60]
11/03 03:24:14 AM | learning_rate: 0.015877852522924715
11/03 03:24:15 AM |   (0/196):Loss 0.1983 Prec@1(1,5) 92.19, 100.00
11/03 03:24:20 AM |   (50/196):Loss 0.2096 Prec@1(1,5) 92.99, 99.85
11/03 03:24:26 AM |   (100/196):Loss 0.2089 Prec@1(1,5) 92.97, 99.84
11/03 03:24:31 AM |   (150/196):Loss 0.2104 Prec@1(1,5) 92.87, 99.85
11/03 03:24:38 AM |  * Acc@1 87.960 Acc@5 99.580
11/03 03:24:38 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:24:38 AM | ----
11/03 03:24:38 AM | Epoch[61]
11/03 03:24:38 AM | learning_rate: 0.01575005252043277
11/03 03:24:39 AM |   (0/196):Loss 0.1555 Prec@1(1,5) 95.31, 99.61
11/03 03:24:45 AM |   (50/196):Loss 0.1998 Prec@1(1,5) 93.34, 99.86
11/03 03:24:50 AM |   (100/196):Loss 0.2035 Prec@1(1,5) 93.08, 99.89
11/03 03:24:56 AM |   (150/196):Loss 0.2044 Prec@1(1,5) 93.09, 99.88
11/03 03:25:03 AM |  * Acc@1 86.840 Acc@5 99.390
11/03 03:25:03 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:25:03 AM | ----
11/03 03:25:03 AM | Epoch[62]
11/03 03:25:03 AM | learning_rate: 0.015620833778521293
11/03 03:25:03 AM |   (0/196):Loss 0.2078 Prec@1(1,5) 92.58, 100.00
11/03 03:25:09 AM |   (50/196):Loss 0.1995 Prec@1(1,5) 93.41, 99.89
11/03 03:25:15 AM |   (100/196):Loss 0.2040 Prec@1(1,5) 93.16, 99.88
11/03 03:25:20 AM |   (150/196):Loss 0.2073 Prec@1(1,5) 93.06, 99.87
11/03 03:25:27 AM |  * Acc@1 85.210 Acc@5 99.260
11/03 03:25:27 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:25:27 AM | ----
11/03 03:25:27 AM | Epoch[63]
11/03 03:25:27 AM | learning_rate: 0.015490228179981302
11/03 03:25:28 AM |   (0/196):Loss 0.1798 Prec@1(1,5) 94.53, 100.00
11/03 03:25:33 AM |   (50/196):Loss 0.2065 Prec@1(1,5) 92.99, 99.88
11/03 03:25:39 AM |   (100/196):Loss 0.2007 Prec@1(1,5) 93.17, 99.87
11/03 03:25:44 AM |   (150/196):Loss 0.2035 Prec@1(1,5) 93.14, 99.85
11/03 03:25:51 AM |  * Acc@1 83.420 Acc@5 98.590
11/03 03:25:51 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:25:51 AM | ----
11/03 03:25:51 AM | Epoch[64]
11/03 03:25:51 AM | learning_rate: 0.01535826794978995
11/03 03:25:52 AM |   (0/196):Loss 0.1869 Prec@1(1,5) 93.75, 100.00
11/03 03:25:57 AM |   (50/196):Loss 0.1970 Prec@1(1,5) 93.33, 99.89
11/03 03:26:03 AM |   (100/196):Loss 0.1965 Prec@1(1,5) 93.43, 99.87
11/03 03:26:09 AM |   (150/196):Loss 0.1997 Prec@1(1,5) 93.34, 99.85
11/03 03:26:15 AM |  * Acc@1 84.800 Acc@5 99.340
11/03 03:26:16 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:26:16 AM | ----
11/03 03:26:16 AM | Epoch[65]
11/03 03:26:16 AM | learning_rate: 0.015224985647159473
11/03 03:26:16 AM |   (0/196):Loss 0.2247 Prec@1(1,5) 92.19, 100.00
11/03 03:26:22 AM |   (50/196):Loss 0.1960 Prec@1(1,5) 93.43, 99.87
11/03 03:26:28 AM |   (100/196):Loss 0.1999 Prec@1(1,5) 93.30, 99.88
11/03 03:26:33 AM |   (150/196):Loss 0.2032 Prec@1(1,5) 93.10, 99.88
11/03 03:26:40 AM |  * Acc@1 87.570 Acc@5 99.420
11/03 03:26:40 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:26:40 AM | ----
11/03 03:26:40 AM | Epoch[66]
11/03 03:26:40 AM | learning_rate: 0.0150904141575037
11/03 03:26:40 AM |   (0/196):Loss 0.2104 Prec@1(1,5) 94.14, 99.61
11/03 03:26:46 AM |   (50/196):Loss 0.2071 Prec@1(1,5) 93.10, 99.85
11/03 03:26:52 AM |   (100/196):Loss 0.2073 Prec@1(1,5) 93.09, 99.88
11/03 03:26:57 AM |   (150/196):Loss 0.2045 Prec@1(1,5) 93.18, 99.88
11/03 03:27:04 AM |  * Acc@1 84.970 Acc@5 99.270
11/03 03:27:04 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:27:04 AM | ----
11/03 03:27:04 AM | Epoch[67]
11/03 03:27:04 AM | learning_rate: 0.014954586684324063
11/03 03:27:05 AM |   (0/196):Loss 0.2203 Prec@1(1,5) 91.02, 100.00
11/03 03:27:11 AM |   (50/196):Loss 0.1817 Prec@1(1,5) 93.78, 99.94
11/03 03:27:16 AM |   (100/196):Loss 0.1858 Prec@1(1,5) 93.68, 99.91
11/03 03:27:22 AM |   (150/196):Loss 0.1921 Prec@1(1,5) 93.51, 99.89
11/03 03:27:29 AM |  * Acc@1 85.190 Acc@5 99.400
11/03 03:27:29 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:27:29 AM | ----
11/03 03:27:29 AM | Epoch[68]
11/03 03:27:29 AM | learning_rate: 0.01481753674101714
11/03 03:27:29 AM |   (0/196):Loss 0.1621 Prec@1(1,5) 94.92, 100.00
11/03 03:27:35 AM |   (50/196):Loss 0.1951 Prec@1(1,5) 93.24, 99.92
11/03 03:27:41 AM |   (100/196):Loss 0.1977 Prec@1(1,5) 93.26, 99.89
11/03 03:27:46 AM |   (150/196):Loss 0.2031 Prec@1(1,5) 93.17, 99.86
11/03 03:27:53 AM |  * Acc@1 86.800 Acc@5 99.300
11/03 03:27:53 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:27:53 AM | ----
11/03 03:27:53 AM | Epoch[69]
11/03 03:27:53 AM | learning_rate: 0.014679298142605723
11/03 03:27:54 AM |   (0/196):Loss 0.2174 Prec@1(1,5) 92.58, 100.00
11/03 03:27:59 AM |   (50/196):Loss 0.1946 Prec@1(1,5) 93.48, 99.87
11/03 03:28:05 AM |   (100/196):Loss 0.2011 Prec@1(1,5) 93.19, 99.87
11/03 03:28:10 AM |   (150/196):Loss 0.2011 Prec@1(1,5) 93.23, 99.87
11/03 03:28:17 AM |  * Acc@1 87.220 Acc@5 99.540
11/03 03:28:17 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:28:17 AM | ----
11/03 03:28:17 AM | Epoch[70]
11/03 03:28:17 AM | learning_rate: 0.014539904997395455
11/03 03:28:18 AM |   (0/196):Loss 0.1700 Prec@1(1,5) 92.58, 100.00
11/03 03:28:23 AM |   (50/196):Loss 0.2014 Prec@1(1,5) 93.18, 99.89
11/03 03:28:29 AM |   (100/196):Loss 0.2019 Prec@1(1,5) 93.17, 99.85
11/03 03:28:35 AM |   (150/196):Loss 0.2010 Prec@1(1,5) 93.26, 99.86
11/03 03:28:42 AM |  * Acc@1 83.770 Acc@5 99.230
11/03 03:28:42 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:28:42 AM | ----
11/03 03:28:42 AM | Epoch[71]
11/03 03:28:42 AM | learning_rate: 0.014399391698559137
11/03 03:28:42 AM |   (0/196):Loss 0.2319 Prec@1(1,5) 92.58, 100.00
11/03 03:28:48 AM |   (50/196):Loss 0.1917 Prec@1(1,5) 93.40, 99.94
11/03 03:28:54 AM |   (100/196):Loss 0.1935 Prec@1(1,5) 93.46, 99.91
11/03 03:28:59 AM |   (150/196):Loss 0.1962 Prec@1(1,5) 93.37, 99.90
11/03 03:29:06 AM |  * Acc@1 84.700 Acc@5 99.290
11/03 03:29:06 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:29:06 AM | ----
11/03 03:29:06 AM | Epoch[72]
11/03 03:29:06 AM | learning_rate: 0.014257792915650715
11/03 03:29:07 AM |   (0/196):Loss 0.1619 Prec@1(1,5) 95.31, 100.00
11/03 03:29:12 AM |   (50/196):Loss 0.1881 Prec@1(1,5) 93.52, 99.89
11/03 03:29:18 AM |   (100/196):Loss 0.1921 Prec@1(1,5) 93.39, 99.89
11/03 03:29:23 AM |   (150/196):Loss 0.1962 Prec@1(1,5) 93.29, 99.87
11/03 03:29:30 AM |  * Acc@1 85.240 Acc@5 99.440
11/03 03:29:31 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:29:31 AM | ----
11/03 03:29:31 AM | Epoch[73]
11/03 03:29:31 AM | learning_rate: 0.014115143586051078
11/03 03:29:31 AM |   (0/196):Loss 0.1924 Prec@1(1,5) 93.75, 99.61
11/03 03:29:37 AM |   (50/196):Loss 0.1911 Prec@1(1,5) 93.60, 99.85
11/03 03:29:42 AM |   (100/196):Loss 0.1863 Prec@1(1,5) 93.79, 99.86
11/03 03:29:48 AM |   (150/196):Loss 0.1912 Prec@1(1,5) 93.53, 99.88
11/03 03:29:55 AM |  * Acc@1 84.640 Acc@5 99.330
11/03 03:29:55 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:29:55 AM | ----
11/03 03:29:55 AM | Epoch[74]
11/03 03:29:55 AM | learning_rate: 0.013971478906347794
11/03 03:29:55 AM |   (0/196):Loss 0.1669 Prec@1(1,5) 94.92, 100.00
11/03 03:30:01 AM |   (50/196):Loss 0.1791 Prec@1(1,5) 93.90, 99.93
11/03 03:30:07 AM |   (100/196):Loss 0.1857 Prec@1(1,5) 93.82, 99.90
11/03 03:30:12 AM |   (150/196):Loss 0.1907 Prec@1(1,5) 93.62, 99.89
11/03 03:30:19 AM |  * Acc@1 88.260 Acc@5 99.610
11/03 03:30:19 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:30:19 AM | ----
11/03 03:30:19 AM | Epoch[75]
11/03 03:30:19 AM | learning_rate: 0.013826834323650889
11/03 03:30:20 AM |   (0/196):Loss 0.2030 Prec@1(1,5) 91.41, 100.00
11/03 03:30:26 AM |   (50/196):Loss 0.1798 Prec@1(1,5) 94.07, 99.92
11/03 03:30:31 AM |   (100/196):Loss 0.1801 Prec@1(1,5) 94.01, 99.88
11/03 03:30:37 AM |   (150/196):Loss 0.1863 Prec@1(1,5) 93.83, 99.87
11/03 03:30:44 AM |  * Acc@1 79.540 Acc@5 98.570
11/03 03:30:44 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:30:44 AM | ----
11/03 03:30:44 AM | Epoch[76]
11/03 03:30:44 AM | learning_rate: 0.013681245526846771
11/03 03:30:44 AM |   (0/196):Loss 0.2129 Prec@1(1,5) 92.19, 100.00
11/03 03:30:50 AM |   (50/196):Loss 0.2055 Prec@1(1,5) 92.99, 99.89
11/03 03:30:56 AM |   (100/196):Loss 0.1966 Prec@1(1,5) 93.33, 99.88
11/03 03:31:01 AM |   (150/196):Loss 0.1942 Prec@1(1,5) 93.47, 99.88
11/03 03:31:08 AM |  * Acc@1 86.200 Acc@5 99.350
11/03 03:31:08 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:31:08 AM | ----
11/03 03:31:08 AM | Epoch[77]
11/03 03:31:08 AM | learning_rate: 0.013534748437792562
11/03 03:31:09 AM |   (0/196):Loss 0.1357 Prec@1(1,5) 95.70, 100.00
11/03 03:31:14 AM |   (50/196):Loss 0.1782 Prec@1(1,5) 94.01, 99.92
11/03 03:31:20 AM |   (100/196):Loss 0.1857 Prec@1(1,5) 93.80, 99.91
11/03 03:31:26 AM |   (150/196):Loss 0.1910 Prec@1(1,5) 93.61, 99.89
11/03 03:31:32 AM |  * Acc@1 87.190 Acc@5 99.410
11/03 03:31:32 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:31:32 AM | ----
11/03 03:31:32 AM | Epoch[78]
11/03 03:31:32 AM | learning_rate: 0.013387379202452906
11/03 03:31:33 AM |   (0/196):Loss 0.1673 Prec@1(1,5) 94.14, 100.00
11/03 03:31:39 AM |   (50/196):Loss 0.1821 Prec@1(1,5) 93.88, 99.92
11/03 03:31:44 AM |   (100/196):Loss 0.1786 Prec@1(1,5) 93.97, 99.91
11/03 03:31:50 AM |   (150/196):Loss 0.1838 Prec@1(1,5) 93.75, 99.90
11/03 03:31:56 AM |  * Acc@1 84.820 Acc@5 99.100
11/03 03:31:56 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:31:56 AM | ----
11/03 03:31:56 AM | Epoch[79]
11/03 03:31:56 AM | learning_rate: 0.013239174181981487
11/03 03:31:57 AM |   (0/196):Loss 0.1868 Prec@1(1,5) 92.97, 100.00
11/03 03:32:03 AM |   (50/196):Loss 0.1683 Prec@1(1,5) 94.65, 99.92
11/03 03:32:08 AM |   (100/196):Loss 0.1725 Prec@1(1,5) 94.46, 99.90
11/03 03:32:14 AM |   (150/196):Loss 0.1782 Prec@1(1,5) 94.15, 99.90
11/03 03:32:21 AM |  * Acc@1 83.220 Acc@5 98.210
11/03 03:32:21 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:32:21 AM | ----
11/03 03:32:21 AM | Epoch[80]
11/03 03:32:21 AM | learning_rate: 0.013090169943749466
11/03 03:32:21 AM |   (0/196):Loss 0.2093 Prec@1(1,5) 93.36, 100.00
11/03 03:32:27 AM |   (50/196):Loss 0.1791 Prec@1(1,5) 94.14, 99.87
11/03 03:32:33 AM |   (100/196):Loss 0.1800 Prec@1(1,5) 94.09, 99.90
11/03 03:32:38 AM |   (150/196):Loss 0.1823 Prec@1(1,5) 93.97, 99.91
11/03 03:32:45 AM |  * Acc@1 86.070 Acc@5 99.110
11/03 03:32:45 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:32:45 AM | ----
11/03 03:32:45 AM | Epoch[81]
11/03 03:32:45 AM | learning_rate: 0.012940403252323032
11/03 03:32:46 AM |   (0/196):Loss 0.1834 Prec@1(1,5) 92.97, 100.00
11/03 03:32:51 AM |   (50/196):Loss 0.1820 Prec@1(1,5) 94.10, 99.92
11/03 03:32:57 AM |   (100/196):Loss 0.1761 Prec@1(1,5) 94.29, 99.91
11/03 03:33:03 AM |   (150/196):Loss 0.1793 Prec@1(1,5) 94.09, 99.91
11/03 03:33:09 AM |  * Acc@1 88.220 Acc@5 99.500
11/03 03:33:09 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:33:09 AM | ----
11/03 03:33:09 AM | Epoch[82]
11/03 03:33:09 AM | learning_rate: 0.012789911060392286
11/03 03:33:10 AM |   (0/196):Loss 0.1281 Prec@1(1,5) 94.92, 100.00
11/03 03:33:16 AM |   (50/196):Loss 0.1768 Prec@1(1,5) 94.11, 99.87
11/03 03:33:21 AM |   (100/196):Loss 0.1751 Prec@1(1,5) 94.07, 99.88
11/03 03:33:27 AM |   (150/196):Loss 0.1807 Prec@1(1,5) 93.91, 99.88
11/03 03:33:33 AM |  * Acc@1 87.350 Acc@5 99.370
11/03 03:33:34 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:33:34 AM | ----
11/03 03:33:34 AM | Epoch[83]
11/03 03:33:34 AM | learning_rate: 0.01263873049965372
11/03 03:33:34 AM |   (0/196):Loss 0.2132 Prec@1(1,5) 92.19, 100.00
11/03 03:33:40 AM |   (50/196):Loss 0.1814 Prec@1(1,5) 93.95, 99.92
11/03 03:33:45 AM |   (100/196):Loss 0.1718 Prec@1(1,5) 94.25, 99.93
11/03 03:33:51 AM |   (150/196):Loss 0.1739 Prec@1(1,5) 94.16, 99.93
11/03 03:33:58 AM |  * Acc@1 87.220 Acc@5 99.240
11/03 03:33:58 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:33:58 AM | ----
11/03 03:33:58 AM | Epoch[84]
11/03 03:33:58 AM | learning_rate: 0.01248689887164854
11/03 03:33:58 AM |   (0/196):Loss 0.1373 Prec@1(1,5) 95.31, 100.00
11/03 03:34:04 AM |   (50/196):Loss 0.1688 Prec@1(1,5) 94.37, 99.95
11/03 03:34:10 AM |   (100/196):Loss 0.1765 Prec@1(1,5) 94.16, 99.93
11/03 03:34:15 AM |   (150/196):Loss 0.1771 Prec@1(1,5) 94.11, 99.92
11/03 03:34:22 AM |  * Acc@1 87.580 Acc@5 99.340
11/03 03:34:22 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:34:22 AM | ----
11/03 03:34:22 AM | Epoch[85]
11/03 03:34:22 AM | learning_rate: 0.01233445363855905
11/03 03:34:23 AM |   (0/196):Loss 0.1861 Prec@1(1,5) 93.75, 100.00
11/03 03:34:29 AM |   (50/196):Loss 0.1700 Prec@1(1,5) 94.23, 99.95
11/03 03:34:34 AM |   (100/196):Loss 0.1760 Prec@1(1,5) 94.08, 99.92
11/03 03:34:40 AM |   (150/196):Loss 0.1732 Prec@1(1,5) 94.24, 99.91
11/03 03:34:47 AM |  * Acc@1 85.800 Acc@5 99.270
11/03 03:34:47 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:34:47 AM | ----
11/03 03:34:47 AM | Epoch[86]
11/03 03:34:47 AM | learning_rate: 0.012181432413965422
11/03 03:34:47 AM |   (0/196):Loss 0.1719 Prec@1(1,5) 95.70, 100.00
11/03 03:34:53 AM |   (50/196):Loss 0.1667 Prec@1(1,5) 94.49, 99.93
11/03 03:34:59 AM |   (100/196):Loss 0.1732 Prec@1(1,5) 94.21, 99.91
11/03 03:35:04 AM |   (150/196):Loss 0.1764 Prec@1(1,5) 94.11, 99.90
11/03 03:35:11 AM |  * Acc@1 86.560 Acc@5 99.290
11/03 03:35:11 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:35:11 AM | ----
11/03 03:35:11 AM | Epoch[87]
11/03 03:35:11 AM | learning_rate: 0.012027872953565121
11/03 03:35:12 AM |   (0/196):Loss 0.1660 Prec@1(1,5) 94.92, 100.00
11/03 03:35:17 AM |   (50/196):Loss 0.1671 Prec@1(1,5) 94.18, 99.93
11/03 03:35:23 AM |   (100/196):Loss 0.1760 Prec@1(1,5) 93.99, 99.91
11/03 03:35:29 AM |   (150/196):Loss 0.1750 Prec@1(1,5) 94.06, 99.91
11/03 03:35:36 AM |  * Acc@1 82.810 Acc@5 98.720
11/03 03:35:36 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:35:36 AM | ----
11/03 03:35:36 AM | Epoch[88]
11/03 03:35:36 AM | learning_rate: 0.011873813145857243
11/03 03:35:36 AM |   (0/196):Loss 0.1547 Prec@1(1,5) 94.14, 99.61
11/03 03:35:42 AM |   (50/196):Loss 0.1538 Prec@1(1,5) 94.99, 99.91
11/03 03:35:47 AM |   (100/196):Loss 0.1629 Prec@1(1,5) 94.59, 99.93
11/03 03:35:53 AM |   (150/196):Loss 0.1677 Prec@1(1,5) 94.38, 99.91
11/03 03:36:00 AM |  * Acc@1 86.210 Acc@5 99.460
11/03 03:36:00 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:36:00 AM | ----
11/03 03:36:00 AM | Epoch[89]
11/03 03:36:00 AM | learning_rate: 0.01171929100279409
11/03 03:36:00 AM |   (0/196):Loss 0.1677 Prec@1(1,5) 94.53, 100.00
11/03 03:36:06 AM |   (50/196):Loss 0.1623 Prec@1(1,5) 94.49, 99.95
11/03 03:36:12 AM |   (100/196):Loss 0.1588 Prec@1(1,5) 94.71, 99.94
11/03 03:36:18 AM |   (150/196):Loss 0.1640 Prec@1(1,5) 94.50, 99.92
11/03 03:36:24 AM |  * Acc@1 86.540 Acc@5 99.540
11/03 03:36:25 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:36:25 AM | ----
11/03 03:36:25 AM | Epoch[90]
11/03 03:36:25 AM | learning_rate: 0.011564344650402304
11/03 03:36:25 AM |   (0/196):Loss 0.1068 Prec@1(1,5) 96.09, 100.00
11/03 03:36:31 AM |   (50/196):Loss 0.1650 Prec@1(1,5) 94.64, 99.92
11/03 03:36:36 AM |   (100/196):Loss 0.1712 Prec@1(1,5) 94.25, 99.92
11/03 03:36:42 AM |   (150/196):Loss 0.1677 Prec@1(1,5) 94.28, 99.93
11/03 03:36:49 AM |  * Acc@1 86.040 Acc@5 99.430
11/03 03:36:49 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:36:49 AM | ----
11/03 03:36:49 AM | Epoch[91]
11/03 03:36:49 AM | learning_rate: 0.011409012319375822
11/03 03:36:49 AM |   (0/196):Loss 0.1665 Prec@1(1,5) 94.53, 100.00
11/03 03:36:55 AM |   (50/196):Loss 0.1686 Prec@1(1,5) 94.29, 99.90
11/03 03:37:01 AM |   (100/196):Loss 0.1719 Prec@1(1,5) 94.27, 99.90
11/03 03:37:07 AM |   (150/196):Loss 0.1699 Prec@1(1,5) 94.33, 99.89
11/03 03:37:13 AM |  * Acc@1 87.220 Acc@5 99.440
11/03 03:37:14 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:37:14 AM | ----
11/03 03:37:14 AM | Epoch[92]
11/03 03:37:14 AM | learning_rate: 0.011253332335643039
11/03 03:37:14 AM |   (0/196):Loss 0.1108 Prec@1(1,5) 96.88, 100.00
11/03 03:37:20 AM |   (50/196):Loss 0.1564 Prec@1(1,5) 94.82, 99.93
11/03 03:37:25 AM |   (100/196):Loss 0.1561 Prec@1(1,5) 94.79, 99.91
11/03 03:37:31 AM |   (150/196):Loss 0.1595 Prec@1(1,5) 94.72, 99.90
11/03 03:37:38 AM |  * Acc@1 86.730 Acc@5 99.480
11/03 03:37:38 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:37:38 AM | ----
11/03 03:37:38 AM | Epoch[93]
11/03 03:37:38 AM | learning_rate: 0.011097343110910448
11/03 03:37:38 AM |   (0/196):Loss 0.2126 Prec@1(1,5) 93.75, 99.61
11/03 03:37:44 AM |   (50/196):Loss 0.1472 Prec@1(1,5) 95.14, 99.93
11/03 03:37:50 AM |   (100/196):Loss 0.1515 Prec@1(1,5) 94.96, 99.91
11/03 03:37:55 AM |   (150/196):Loss 0.1573 Prec@1(1,5) 94.73, 99.93
11/03 03:38:02 AM |  * Acc@1 86.720 Acc@5 99.510
11/03 03:38:02 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:38:02 AM | ----
11/03 03:38:02 AM | Epoch[94]
11/03 03:38:02 AM | learning_rate: 0.010941083133185139
11/03 03:38:03 AM |   (0/196):Loss 0.1321 Prec@1(1,5) 96.48, 99.61
11/03 03:38:08 AM |   (50/196):Loss 0.1657 Prec@1(1,5) 94.39, 99.91
11/03 03:38:14 AM |   (100/196):Loss 0.1601 Prec@1(1,5) 94.52, 99.91
11/03 03:38:20 AM |   (150/196):Loss 0.1596 Prec@1(1,5) 94.60, 99.91
11/03 03:38:26 AM |  * Acc@1 88.420 Acc@5 99.280
11/03 03:38:26 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:38:26 AM | ----
11/03 03:38:26 AM | Epoch[95]
11/03 03:38:26 AM | learning_rate: 0.010784590957278446
11/03 03:38:27 AM |   (0/196):Loss 0.1620 Prec@1(1,5) 94.14, 100.00
11/03 03:38:33 AM |   (50/196):Loss 0.1601 Prec@1(1,5) 94.45, 99.92
11/03 03:38:39 AM |   (100/196):Loss 0.1568 Prec@1(1,5) 94.71, 99.91
11/03 03:38:44 AM |   (150/196):Loss 0.1549 Prec@1(1,5) 94.75, 99.91
11/03 03:38:51 AM |  * Acc@1 87.300 Acc@5 99.270
11/03 03:38:51 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:38:51 AM | ----
11/03 03:38:51 AM | Epoch[96]
11/03 03:38:51 AM | learning_rate: 0.01062790519529313
11/03 03:38:52 AM |   (0/196):Loss 0.1788 Prec@1(1,5) 94.92, 100.00
11/03 03:38:57 AM |   (50/196):Loss 0.1352 Prec@1(1,5) 95.67, 99.95
11/03 03:39:03 AM |   (100/196):Loss 0.1518 Prec@1(1,5) 94.82, 99.94
11/03 03:39:09 AM |   (150/196):Loss 0.1531 Prec@1(1,5) 94.82, 99.93
11/03 03:39:16 AM |  * Acc@1 87.600 Acc@5 99.480
11/03 03:39:16 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:39:16 AM | ----
11/03 03:39:16 AM | Epoch[97]
11/03 03:39:16 AM | learning_rate: 0.01047106450709642
11/03 03:39:16 AM |   (0/196):Loss 0.1513 Prec@1(1,5) 96.48, 100.00
11/03 03:39:22 AM |   (50/196):Loss 0.1487 Prec@1(1,5) 95.08, 99.95
11/03 03:39:28 AM |   (100/196):Loss 0.1460 Prec@1(1,5) 95.22, 99.95
11/03 03:39:33 AM |   (150/196):Loss 0.1502 Prec@1(1,5) 95.00, 99.94
11/03 03:39:40 AM |  * Acc@1 85.860 Acc@5 99.590
11/03 03:39:40 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:39:40 AM | ----
11/03 03:39:40 AM | Epoch[98]
11/03 03:39:40 AM | learning_rate: 0.010314107590781278
11/03 03:39:41 AM |   (0/196):Loss 0.1583 Prec@1(1,5) 94.14, 100.00
11/03 03:39:47 AM |   (50/196):Loss 0.1399 Prec@1(1,5) 95.29, 99.95
11/03 03:39:52 AM |   (100/196):Loss 0.1423 Prec@1(1,5) 95.34, 99.93
11/03 03:39:58 AM |   (150/196):Loss 0.1449 Prec@1(1,5) 95.21, 99.94
11/03 03:40:05 AM |  * Acc@1 88.770 Acc@5 99.600
11/03 03:40:05 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:40:05 AM | ----
11/03 03:40:05 AM | Epoch[99]
11/03 03:40:05 AM | learning_rate: 0.010157073173118201
11/03 03:40:05 AM |   (0/196):Loss 0.1253 Prec@1(1,5) 94.92, 100.00
11/03 03:40:11 AM |   (50/196):Loss 0.1435 Prec@1(1,5) 95.15, 99.95
11/03 03:40:17 AM |   (100/196):Loss 0.1437 Prec@1(1,5) 95.28, 99.94
11/03 03:40:22 AM |   (150/196):Loss 0.1514 Prec@1(1,5) 95.04, 99.93
11/03 03:40:29 AM |  * Acc@1 87.540 Acc@5 99.500
11/03 03:40:29 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:40:29 AM | ----
11/03 03:40:29 AM | Epoch[100]
11/03 03:40:29 AM | learning_rate: 0.009999999999999993
11/03 03:40:30 AM |   (0/196):Loss 0.1545 Prec@1(1,5) 95.70, 100.00
11/03 03:40:35 AM |   (50/196):Loss 0.1460 Prec@1(1,5) 95.37, 99.95
11/03 03:40:41 AM |   (100/196):Loss 0.1488 Prec@1(1,5) 95.18, 99.93
11/03 03:40:47 AM |   (150/196):Loss 0.1488 Prec@1(1,5) 95.12, 99.92
11/03 03:40:54 AM |  * Acc@1 88.860 Acc@5 99.560
11/03 03:40:54 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:40:54 AM | ----
11/03 03:40:54 AM | Epoch[101]
11/03 03:40:54 AM | learning_rate: 0.009842926826881789
11/03 03:40:54 AM |   (0/196):Loss 0.0745 Prec@1(1,5) 98.44, 100.00
11/03 03:41:00 AM |   (50/196):Loss 0.1510 Prec@1(1,5) 95.10, 99.95
11/03 03:41:05 AM |   (100/196):Loss 0.1471 Prec@1(1,5) 95.09, 99.96
11/03 03:41:11 AM |   (150/196):Loss 0.1506 Prec@1(1,5) 94.97, 99.94
11/03 03:41:18 AM |  * Acc@1 89.140 Acc@5 99.590
11/03 03:41:18 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:41:18 AM | ----
11/03 03:41:18 AM | Epoch[102]
11/03 03:41:18 AM | learning_rate: 0.00968589240921871
11/03 03:41:18 AM |   (0/196):Loss 0.1440 Prec@1(1,5) 96.48, 100.00
11/03 03:41:24 AM |   (50/196):Loss 0.1377 Prec@1(1,5) 95.56, 99.95
11/03 03:41:30 AM |   (100/196):Loss 0.1413 Prec@1(1,5) 95.33, 99.95
11/03 03:41:35 AM |   (150/196):Loss 0.1441 Prec@1(1,5) 95.24, 99.93
11/03 03:41:42 AM |  * Acc@1 86.200 Acc@5 99.490
11/03 03:41:42 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:41:42 AM | ----
11/03 03:41:42 AM | Epoch[103]
11/03 03:41:42 AM | learning_rate: 0.009528935492903567
11/03 03:41:43 AM |   (0/196):Loss 0.1913 Prec@1(1,5) 94.53, 99.61
11/03 03:41:49 AM |   (50/196):Loss 0.1447 Prec@1(1,5) 95.38, 99.96
11/03 03:41:54 AM |   (100/196):Loss 0.1399 Prec@1(1,5) 95.45, 99.96
11/03 03:42:00 AM |   (150/196):Loss 0.1402 Prec@1(1,5) 95.34, 99.96
11/03 03:42:07 AM |  * Acc@1 87.070 Acc@5 99.550
11/03 03:42:07 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:42:07 AM | ----
11/03 03:42:07 AM | Epoch[104]
11/03 03:42:07 AM | learning_rate: 0.00937209480470686
11/03 03:42:07 AM |   (0/196):Loss 0.1434 Prec@1(1,5) 94.53, 100.00
11/03 03:42:13 AM |   (50/196):Loss 0.1310 Prec@1(1,5) 95.60, 99.97
11/03 03:42:19 AM |   (100/196):Loss 0.1337 Prec@1(1,5) 95.54, 99.96
11/03 03:42:24 AM |   (150/196):Loss 0.1343 Prec@1(1,5) 95.52, 99.96
11/03 03:42:31 AM |  * Acc@1 86.680 Acc@5 99.370
11/03 03:42:31 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:42:31 AM | ----
11/03 03:42:31 AM | Epoch[105]
11/03 03:42:31 AM | learning_rate: 0.009215409042721546
11/03 03:42:32 AM |   (0/196):Loss 0.0897 Prec@1(1,5) 97.66, 100.00
11/03 03:42:37 AM |   (50/196):Loss 0.1412 Prec@1(1,5) 95.44, 99.97
11/03 03:42:43 AM |   (100/196):Loss 0.1307 Prec@1(1,5) 95.69, 99.97
11/03 03:42:49 AM |   (150/196):Loss 0.1337 Prec@1(1,5) 95.58, 99.95
11/03 03:42:55 AM |  * Acc@1 89.210 Acc@5 99.500
11/03 03:42:56 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:42:56 AM | ----
11/03 03:42:56 AM | Epoch[106]
11/03 03:42:56 AM | learning_rate: 0.009058916866814851
11/03 03:42:56 AM |   (0/196):Loss 0.1244 Prec@1(1,5) 94.53, 100.00
11/03 03:43:02 AM |   (50/196):Loss 0.1390 Prec@1(1,5) 95.37, 99.95
11/03 03:43:08 AM |   (100/196):Loss 0.1358 Prec@1(1,5) 95.43, 99.95
11/03 03:43:13 AM |   (150/196):Loss 0.1372 Prec@1(1,5) 95.44, 99.95
11/03 03:43:20 AM |  * Acc@1 86.810 Acc@5 99.360
11/03 03:43:20 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:43:20 AM | ----
11/03 03:43:20 AM | Epoch[107]
11/03 03:43:20 AM | learning_rate: 0.008902656889089542
11/03 03:43:21 AM |   (0/196):Loss 0.1144 Prec@1(1,5) 96.09, 99.61
11/03 03:43:26 AM |   (50/196):Loss 0.1277 Prec@1(1,5) 95.93, 99.95
11/03 03:43:32 AM |   (100/196):Loss 0.1286 Prec@1(1,5) 95.83, 99.95
11/03 03:43:38 AM |   (150/196):Loss 0.1303 Prec@1(1,5) 95.69, 99.95
11/03 03:43:45 AM |  * Acc@1 88.870 Acc@5 99.510
11/03 03:43:45 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:43:45 AM | ----
11/03 03:43:45 AM | Epoch[108]
11/03 03:43:45 AM | learning_rate: 0.008746667664356953
11/03 03:43:45 AM |   (0/196):Loss 0.1197 Prec@1(1,5) 95.31, 100.00
11/03 03:43:51 AM |   (50/196):Loss 0.1310 Prec@1(1,5) 95.85, 99.95
11/03 03:43:57 AM |   (100/196):Loss 0.1333 Prec@1(1,5) 95.69, 99.94
11/03 03:44:02 AM |   (150/196):Loss 0.1330 Prec@1(1,5) 95.69, 99.95
11/03 03:44:09 AM |  * Acc@1 84.720 Acc@5 99.520
11/03 03:44:09 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:44:09 AM | ----
11/03 03:44:09 AM | Epoch[109]
11/03 03:44:09 AM | learning_rate: 0.008590987680624171
11/03 03:44:10 AM |   (0/196):Loss 0.0919 Prec@1(1,5) 97.27, 99.61
11/03 03:44:15 AM |   (50/196):Loss 0.1229 Prec@1(1,5) 95.91, 99.94
11/03 03:44:21 AM |   (100/196):Loss 0.1233 Prec@1(1,5) 95.83, 99.97
11/03 03:44:27 AM |   (150/196):Loss 0.1229 Prec@1(1,5) 95.90, 99.96
11/03 03:44:34 AM |  * Acc@1 85.630 Acc@5 99.360
11/03 03:44:34 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:44:34 AM | ----
11/03 03:44:34 AM | Epoch[110]
11/03 03:44:34 AM | learning_rate: 0.008435655349597688
11/03 03:44:34 AM |   (0/196):Loss 0.0873 Prec@1(1,5) 96.88, 100.00
11/03 03:44:40 AM |   (50/196):Loss 0.1162 Prec@1(1,5) 96.18, 99.98
11/03 03:44:45 AM |   (100/196):Loss 0.1194 Prec@1(1,5) 96.11, 99.97
11/03 03:44:51 AM |   (150/196):Loss 0.1264 Prec@1(1,5) 95.84, 99.97
11/03 03:44:58 AM |  * Acc@1 88.750 Acc@5 99.570
11/03 03:44:58 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:44:58 AM | ----
11/03 03:44:58 AM | Epoch[111]
11/03 03:44:58 AM | learning_rate: 0.0082807089972059
11/03 03:44:58 AM |   (0/196):Loss 0.0700 Prec@1(1,5) 97.66, 100.00
11/03 03:45:04 AM |   (50/196):Loss 0.1206 Prec@1(1,5) 95.94, 99.94
11/03 03:45:10 AM |   (100/196):Loss 0.1198 Prec@1(1,5) 96.05, 99.96
11/03 03:45:16 AM |   (150/196):Loss 0.1214 Prec@1(1,5) 96.00, 99.95
11/03 03:45:22 AM |  * Acc@1 87.300 Acc@5 99.260
11/03 03:45:22 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:45:22 AM | ----
11/03 03:45:22 AM | Epoch[112]
11/03 03:45:22 AM | learning_rate: 0.008126186854142752
11/03 03:45:23 AM |   (0/196):Loss 0.0882 Prec@1(1,5) 97.27, 100.00
11/03 03:45:29 AM |   (50/196):Loss 0.1224 Prec@1(1,5) 95.87, 99.95
11/03 03:45:34 AM |   (100/196):Loss 0.1201 Prec@1(1,5) 95.99, 99.96
11/03 03:45:40 AM |   (150/196):Loss 0.1261 Prec@1(1,5) 95.79, 99.95
11/03 03:45:47 AM |  * Acc@1 89.570 Acc@5 99.510
11/03 03:45:47 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:45:47 AM | ----
11/03 03:45:47 AM | Epoch[113]
11/03 03:45:47 AM | learning_rate: 0.007972127046434874
11/03 03:45:47 AM |   (0/196):Loss 0.1752 Prec@1(1,5) 93.75, 100.00
11/03 03:45:53 AM |   (50/196):Loss 0.1278 Prec@1(1,5) 95.74, 99.96
11/03 03:45:59 AM |   (100/196):Loss 0.1258 Prec@1(1,5) 95.79, 99.97
11/03 03:46:04 AM |   (150/196):Loss 0.1249 Prec@1(1,5) 95.87, 99.95
11/03 03:46:11 AM |  * Acc@1 89.010 Acc@5 99.370
11/03 03:46:11 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:46:11 AM | ----
11/03 03:46:11 AM | Epoch[114]
11/03 03:46:11 AM | learning_rate: 0.007818567586034575
11/03 03:46:12 AM |   (0/196):Loss 0.1116 Prec@1(1,5) 96.48, 100.00
11/03 03:46:18 AM |   (50/196):Loss 0.1099 Prec@1(1,5) 96.33, 99.98
11/03 03:46:23 AM |   (100/196):Loss 0.1190 Prec@1(1,5) 96.04, 99.96
11/03 03:46:29 AM |   (150/196):Loss 0.1225 Prec@1(1,5) 95.91, 99.95
11/03 03:46:36 AM |  * Acc@1 88.040 Acc@5 99.660
11/03 03:46:36 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:46:36 AM | ----
11/03 03:46:36 AM | Epoch[115]
11/03 03:46:36 AM | learning_rate: 0.007665546361440943
11/03 03:46:36 AM |   (0/196):Loss 0.1039 Prec@1(1,5) 96.88, 100.00
11/03 03:46:42 AM |   (50/196):Loss 0.1165 Prec@1(1,5) 96.21, 99.97
11/03 03:46:48 AM |   (100/196):Loss 0.1156 Prec@1(1,5) 96.21, 99.97
11/03 03:46:53 AM |   (150/196):Loss 0.1171 Prec@1(1,5) 96.16, 99.97
11/03 03:47:00 AM |  * Acc@1 88.590 Acc@5 99.580
11/03 03:47:00 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:47:00 AM | ----
11/03 03:47:00 AM | Epoch[116]
11/03 03:47:00 AM | learning_rate: 0.00751310112835145
11/03 03:47:01 AM |   (0/196):Loss 0.1172 Prec@1(1,5) 95.31, 100.00
11/03 03:47:07 AM |   (50/196):Loss 0.1158 Prec@1(1,5) 96.21, 99.97
11/03 03:47:12 AM |   (100/196):Loss 0.1171 Prec@1(1,5) 96.10, 99.96
11/03 03:47:18 AM |   (150/196):Loss 0.1191 Prec@1(1,5) 96.00, 99.96
11/03 03:47:25 AM |  * Acc@1 88.830 Acc@5 99.340
11/03 03:47:25 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:47:25 AM | ----
11/03 03:47:25 AM | Epoch[117]
11/03 03:47:25 AM | learning_rate: 0.007361269500346269
11/03 03:47:25 AM |   (0/196):Loss 0.0824 Prec@1(1,5) 96.48, 100.00
11/03 03:47:31 AM |   (50/196):Loss 0.1141 Prec@1(1,5) 96.16, 99.96
11/03 03:47:37 AM |   (100/196):Loss 0.1156 Prec@1(1,5) 96.14, 99.96
11/03 03:47:42 AM |   (150/196):Loss 0.1187 Prec@1(1,5) 96.08, 99.95
11/03 03:47:49 AM |  * Acc@1 89.160 Acc@5 99.580
11/03 03:47:49 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:47:49 AM | ----
11/03 03:47:49 AM | Epoch[118]
11/03 03:47:49 AM | learning_rate: 0.007210088939607706
11/03 03:47:50 AM |   (0/196):Loss 0.1151 Prec@1(1,5) 96.48, 100.00
11/03 03:47:55 AM |   (50/196):Loss 0.0947 Prec@1(1,5) 96.93, 99.98
11/03 03:48:01 AM |   (100/196):Loss 0.0985 Prec@1(1,5) 96.68, 99.97
11/03 03:48:06 AM |   (150/196):Loss 0.1036 Prec@1(1,5) 96.48, 99.97
11/03 03:48:13 AM |  * Acc@1 89.030 Acc@5 99.580
11/03 03:48:13 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:48:13 AM | ----
11/03 03:48:13 AM | Epoch[119]
11/03 03:48:13 AM | learning_rate: 0.00705959674767696
11/03 03:48:14 AM |   (0/196):Loss 0.1196 Prec@1(1,5) 94.92, 100.00
11/03 03:48:20 AM |   (50/196):Loss 0.0989 Prec@1(1,5) 96.82, 99.98
11/03 03:48:25 AM |   (100/196):Loss 0.1013 Prec@1(1,5) 96.67, 99.97
11/03 03:48:31 AM |   (150/196):Loss 0.1020 Prec@1(1,5) 96.64, 99.97
11/03 03:48:38 AM |  * Acc@1 88.560 Acc@5 99.480
11/03 03:48:38 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:48:38 AM | ----
11/03 03:48:38 AM | Epoch[120]
11/03 03:48:38 AM | learning_rate: 0.006909830056250527
11/03 03:48:38 AM |   (0/196):Loss 0.0926 Prec@1(1,5) 97.66, 100.00
11/03 03:48:44 AM |   (50/196):Loss 0.1160 Prec@1(1,5) 96.21, 99.97
11/03 03:48:50 AM |   (100/196):Loss 0.1104 Prec@1(1,5) 96.36, 99.98
11/03 03:48:55 AM |   (150/196):Loss 0.1095 Prec@1(1,5) 96.33, 99.97
11/03 03:49:02 AM |  * Acc@1 89.490 Acc@5 99.570
11/03 03:49:02 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:49:02 AM | ----
11/03 03:49:02 AM | Epoch[121]
11/03 03:49:02 AM | learning_rate: 0.0067608258180185034
11/03 03:49:03 AM |   (0/196):Loss 0.1156 Prec@1(1,5) 96.09, 100.00
11/03 03:49:09 AM |   (50/196):Loss 0.1062 Prec@1(1,5) 96.43, 99.95
11/03 03:49:14 AM |   (100/196):Loss 0.1022 Prec@1(1,5) 96.69, 99.95
11/03 03:49:20 AM |   (150/196):Loss 0.1059 Prec@1(1,5) 96.55, 99.95
11/03 03:49:27 AM |  * Acc@1 89.290 Acc@5 99.540
11/03 03:49:27 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:49:27 AM | ----
11/03 03:49:27 AM | Epoch[122]
11/03 03:49:27 AM | learning_rate: 0.006612620797547084
11/03 03:49:27 AM |   (0/196):Loss 0.0689 Prec@1(1,5) 98.05, 100.00
11/03 03:49:33 AM |   (50/196):Loss 0.1033 Prec@1(1,5) 96.74, 99.94
11/03 03:49:39 AM |   (100/196):Loss 0.1050 Prec@1(1,5) 96.63, 99.96
11/03 03:49:44 AM |   (150/196):Loss 0.1065 Prec@1(1,5) 96.52, 99.95
11/03 03:49:51 AM |  * Acc@1 90.330 Acc@5 99.640
11/03 03:49:51 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:49:51 AM | ----
11/03 03:49:51 AM | Epoch[123]
11/03 03:49:51 AM | learning_rate: 0.006465251562207428
11/03 03:49:52 AM |   (0/196):Loss 0.0825 Prec@1(1,5) 96.88, 100.00
11/03 03:49:57 AM |   (50/196):Loss 0.1024 Prec@1(1,5) 96.61, 99.98
11/03 03:50:03 AM |   (100/196):Loss 0.1040 Prec@1(1,5) 96.59, 99.97
11/03 03:50:09 AM |   (150/196):Loss 0.1031 Prec@1(1,5) 96.65, 99.97
11/03 03:50:15 AM |  * Acc@1 89.660 Acc@5 99.680
11/03 03:50:16 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:50:16 AM | ----
11/03 03:50:16 AM | Epoch[124]
11/03 03:50:16 AM | learning_rate: 0.006318754473153221
11/03 03:50:16 AM |   (0/196):Loss 0.0696 Prec@1(1,5) 98.05, 100.00
11/03 03:50:22 AM |   (50/196):Loss 0.0979 Prec@1(1,5) 96.67, 99.97
11/03 03:50:28 AM |   (100/196):Loss 0.0998 Prec@1(1,5) 96.68, 99.97
11/03 03:50:33 AM |   (150/196):Loss 0.1000 Prec@1(1,5) 96.67, 99.97
11/03 03:50:40 AM |  * Acc@1 89.580 Acc@5 99.490
11/03 03:50:40 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:50:40 AM | ----
11/03 03:50:40 AM | Epoch[125]
11/03 03:50:40 AM | learning_rate: 0.006173165676349103
11/03 03:50:41 AM |   (0/196):Loss 0.0396 Prec@1(1,5) 99.61, 100.00
11/03 03:50:46 AM |   (50/196):Loss 0.0985 Prec@1(1,5) 96.92, 99.97
11/03 03:50:52 AM |   (100/196):Loss 0.0951 Prec@1(1,5) 97.03, 99.97
11/03 03:50:58 AM |   (150/196):Loss 0.0955 Prec@1(1,5) 96.91, 99.97
11/03 03:51:05 AM |  * Acc@1 90.090 Acc@5 99.560
11/03 03:51:05 AM | =>Best accuracy 91.070 (at epoch 2)
11/03 03:51:05 AM | ----
11/03 03:51:05 AM | Epoch[126]
11/03 03:51:05 AM | learning_rate: 0.006028521093652191
11/03 03:51:05 AM |   (0/196):Loss 0.1419 Prec@1(1,5) 95.70, 100.00
11/03 03:51:11 AM |   (50/196):Loss 0.0947 Prec@1(1,5) 96.99, 99.98
11/03 03:51:16 AM |   (100/196):Loss 0.0934 Prec@1(1,5) 96.99, 99.97
11/03 03:51:22 AM |   (150/196):Loss 0.0940 Prec@1(1,5) 96.94, 99.97
11/03 03:51:29 AM |  * Acc@1 91.180 Acc@5 99.670
11/03 03:51:29 AM | =>Best accuracy 91.180 (at epoch 126)
11/03 03:51:29 AM | ----
11/03 03:51:29 AM | Epoch[127]
11/03 03:51:29 AM | learning_rate: 0.005884856413948911
11/03 03:51:30 AM |   (0/196):Loss 0.0765 Prec@1(1,5) 97.66, 99.61
11/03 03:51:35 AM |   (50/196):Loss 0.0832 Prec@1(1,5) 97.30, 99.98
11/03 03:51:41 AM |   (100/196):Loss 0.0848 Prec@1(1,5) 97.27, 99.98
11/03 03:51:46 AM |   (150/196):Loss 0.0878 Prec@1(1,5) 97.14, 99.96
11/03 03:51:53 AM |  * Acc@1 90.530 Acc@5 99.690
11/03 03:51:53 AM | =>Best accuracy 91.180 (at epoch 126)
11/03 03:51:53 AM | ----
11/03 03:51:53 AM | Epoch[128]
11/03 03:51:53 AM | learning_rate: 0.005742207084349272
11/03 03:51:54 AM |   (0/196):Loss 0.1271 Prec@1(1,5) 95.31, 100.00
11/03 03:51:59 AM |   (50/196):Loss 0.0900 Prec@1(1,5) 97.10, 99.97
11/03 03:52:05 AM |   (100/196):Loss 0.0886 Prec@1(1,5) 97.20, 99.97
11/03 03:52:10 AM |   (150/196):Loss 0.0903 Prec@1(1,5) 97.09, 99.97
11/03 03:52:17 AM |  * Acc@1 88.660 Acc@5 99.480
11/03 03:52:17 AM | =>Best accuracy 91.180 (at epoch 126)
11/03 03:52:17 AM | ----
11/03 03:52:17 AM | Epoch[129]
11/03 03:52:17 AM | learning_rate: 0.005600608301440847
11/03 03:52:18 AM |   (0/196):Loss 0.0633 Prec@1(1,5) 97.66, 100.00
11/03 03:52:23 AM |   (50/196):Loss 0.0939 Prec@1(1,5) 96.98, 99.97
11/03 03:52:29 AM |   (100/196):Loss 0.0984 Prec@1(1,5) 96.76, 99.97
11/03 03:52:34 AM |   (150/196):Loss 0.0979 Prec@1(1,5) 96.76, 99.97
11/03 03:52:41 AM |  * Acc@1 90.400 Acc@5 99.560
11/03 03:52:41 AM | =>Best accuracy 91.180 (at epoch 126)
11/03 03:52:41 AM | ----
11/03 03:52:42 AM | Epoch[130]
11/03 03:52:42 AM | learning_rate: 0.005460095002604532
11/03 03:52:42 AM |   (0/196):Loss 0.0852 Prec@1(1,5) 97.27, 100.00
11/03 03:52:48 AM |   (50/196):Loss 0.0792 Prec@1(1,5) 97.53, 99.96
11/03 03:52:53 AM |   (100/196):Loss 0.0759 Prec@1(1,5) 97.62, 99.97
11/03 03:52:59 AM |   (150/196):Loss 0.0806 Prec@1(1,5) 97.39, 99.98
11/03 03:53:06 AM |  * Acc@1 90.430 Acc@5 99.610
11/03 03:53:06 AM | =>Best accuracy 91.180 (at epoch 126)
11/03 03:53:06 AM | ----
11/03 03:53:06 AM | Epoch[131]
11/03 03:53:06 AM | learning_rate: 0.005320701857394267
11/03 03:53:07 AM |   (0/196):Loss 0.0853 Prec@1(1,5) 96.88, 100.00
11/03 03:53:12 AM |   (50/196):Loss 0.0784 Prec@1(1,5) 97.43, 99.98
11/03 03:53:18 AM |   (100/196):Loss 0.0767 Prec@1(1,5) 97.52, 99.98
11/03 03:53:23 AM |   (150/196):Loss 0.0827 Prec@1(1,5) 97.35, 99.98
11/03 03:53:30 AM |  * Acc@1 91.330 Acc@5 99.700
11/03 03:53:30 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:53:30 AM | ----
11/03 03:53:30 AM | Epoch[132]
11/03 03:53:30 AM | learning_rate: 0.005182463258982845
11/03 03:53:31 AM |   (0/196):Loss 0.0598 Prec@1(1,5) 98.05, 100.00
11/03 03:53:37 AM |   (50/196):Loss 0.0689 Prec@1(1,5) 97.86, 99.98
11/03 03:53:42 AM |   (100/196):Loss 0.0719 Prec@1(1,5) 97.75, 99.99
11/03 03:53:48 AM |   (150/196):Loss 0.0765 Prec@1(1,5) 97.52, 99.98
11/03 03:53:55 AM |  * Acc@1 90.370 Acc@5 99.540
11/03 03:53:55 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:53:55 AM | ----
11/03 03:53:55 AM | Epoch[133]
11/03 03:53:55 AM | learning_rate: 0.005045413315675923
11/03 03:53:55 AM |   (0/196):Loss 0.1331 Prec@1(1,5) 95.31, 99.61
11/03 03:54:01 AM |   (50/196):Loss 0.0738 Prec@1(1,5) 97.60, 99.98
11/03 03:54:07 AM |   (100/196):Loss 0.0785 Prec@1(1,5) 97.38, 99.98
11/03 03:54:12 AM |   (150/196):Loss 0.0791 Prec@1(1,5) 97.39, 99.98
11/03 03:54:19 AM |  * Acc@1 88.600 Acc@5 99.530
11/03 03:54:19 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:54:19 AM | ----
11/03 03:54:19 AM | Epoch[134]
11/03 03:54:19 AM | learning_rate: 0.0049095858424962864
11/03 03:54:20 AM |   (0/196):Loss 0.0842 Prec@1(1,5) 97.66, 100.00
11/03 03:54:26 AM |   (50/196):Loss 0.0747 Prec@1(1,5) 97.59, 99.99
11/03 03:54:31 AM |   (100/196):Loss 0.0780 Prec@1(1,5) 97.49, 99.99
11/03 03:54:37 AM |   (150/196):Loss 0.0793 Prec@1(1,5) 97.46, 99.99
11/03 03:54:44 AM |  * Acc@1 89.620 Acc@5 99.520
11/03 03:54:44 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:54:44 AM | ----
11/03 03:54:44 AM | Epoch[135]
11/03 03:54:44 AM | learning_rate: 0.004775014352840511
11/03 03:54:45 AM |   (0/196):Loss 0.0841 Prec@1(1,5) 97.66, 100.00
11/03 03:54:50 AM |   (50/196):Loss 0.0766 Prec@1(1,5) 97.59, 99.99
11/03 03:54:56 AM |   (100/196):Loss 0.0737 Prec@1(1,5) 97.72, 99.99
11/03 03:55:01 AM |   (150/196):Loss 0.0728 Prec@1(1,5) 97.72, 99.99
11/03 03:55:08 AM |  * Acc@1 89.190 Acc@5 99.420
11/03 03:55:08 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:55:08 AM | ----
11/03 03:55:08 AM | Epoch[136]
11/03 03:55:08 AM | learning_rate: 0.0046417320502100306
11/03 03:55:09 AM |   (0/196):Loss 0.1118 Prec@1(1,5) 96.48, 100.00
11/03 03:55:15 AM |   (50/196):Loss 0.0723 Prec@1(1,5) 97.63, 99.99
11/03 03:55:20 AM |   (100/196):Loss 0.0678 Prec@1(1,5) 97.83, 99.98
11/03 03:55:26 AM |   (150/196):Loss 0.0690 Prec@1(1,5) 97.79, 99.98
11/03 03:55:33 AM |  * Acc@1 90.100 Acc@5 99.620
11/03 03:55:33 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:55:33 AM | ----
11/03 03:55:33 AM | Epoch[137]
11/03 03:55:33 AM | learning_rate: 0.004509771820018681
11/03 03:55:33 AM |   (0/196):Loss 0.0628 Prec@1(1,5) 98.05, 100.00
11/03 03:55:39 AM |   (50/196):Loss 0.0680 Prec@1(1,5) 97.82, 99.98
11/03 03:55:45 AM |   (100/196):Loss 0.0653 Prec@1(1,5) 97.97, 99.98
11/03 03:55:50 AM |   (150/196):Loss 0.0684 Prec@1(1,5) 97.83, 99.98
11/03 03:55:57 AM |  * Acc@1 90.020 Acc@5 99.610
11/03 03:55:57 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:55:57 AM | ----
11/03 03:55:57 AM | Epoch[138]
11/03 03:55:57 AM | learning_rate: 0.0043791662214786925
11/03 03:55:58 AM |   (0/196):Loss 0.0603 Prec@1(1,5) 98.05, 100.00
11/03 03:56:04 AM |   (50/196):Loss 0.0668 Prec@1(1,5) 97.78, 99.99
11/03 03:56:09 AM |   (100/196):Loss 0.0630 Prec@1(1,5) 97.98, 99.99
11/03 03:56:15 AM |   (150/196):Loss 0.0659 Prec@1(1,5) 97.83, 99.99
11/03 03:56:22 AM |  * Acc@1 91.020 Acc@5 99.640
11/03 03:56:22 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:56:22 AM | ----
11/03 03:56:22 AM | Epoch[139]
11/03 03:56:22 AM | learning_rate: 0.004249947479567214
11/03 03:56:22 AM |   (0/196):Loss 0.0641 Prec@1(1,5) 98.44, 100.00
11/03 03:56:28 AM |   (50/196):Loss 0.0582 Prec@1(1,5) 98.19, 99.99
11/03 03:56:34 AM |   (100/196):Loss 0.0594 Prec@1(1,5) 98.10, 99.99
11/03 03:56:39 AM |   (150/196):Loss 0.0614 Prec@1(1,5) 98.11, 99.98
11/03 03:56:46 AM |  * Acc@1 88.720 Acc@5 99.520
11/03 03:56:46 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:56:46 AM | ----
11/03 03:56:46 AM | Epoch[140]
11/03 03:56:46 AM | learning_rate: 0.0041221474770752695
11/03 03:56:47 AM |   (0/196):Loss 0.0828 Prec@1(1,5) 96.88, 100.00
11/03 03:56:52 AM |   (50/196):Loss 0.0651 Prec@1(1,5) 97.92, 100.00
11/03 03:56:58 AM |   (100/196):Loss 0.0630 Prec@1(1,5) 98.00, 100.00
11/03 03:57:03 AM |   (150/196):Loss 0.0637 Prec@1(1,5) 97.98, 99.99
11/03 03:57:10 AM |  * Acc@1 90.910 Acc@5 99.600
11/03 03:57:11 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:57:11 AM | ----
11/03 03:57:11 AM | Epoch[141]
11/03 03:57:11 AM | learning_rate: 0.003995797746741161
11/03 03:57:11 AM |   (0/196):Loss 0.0372 Prec@1(1,5) 99.22, 100.00
11/03 03:57:17 AM |   (50/196):Loss 0.0714 Prec@1(1,5) 97.61, 99.97
11/03 03:57:22 AM |   (100/196):Loss 0.0616 Prec@1(1,5) 98.01, 99.98
11/03 03:57:28 AM |   (150/196):Loss 0.0600 Prec@1(1,5) 98.08, 99.99
11/03 03:57:35 AM |  * Acc@1 89.260 Acc@5 99.650
11/03 03:57:35 AM | =>Best accuracy 91.330 (at epoch 131)
11/03 03:57:35 AM | ----
11/03 03:57:35 AM | Epoch[142]
11/03 03:57:35 AM | learning_rate: 0.003870929463470234
11/03 03:57:35 AM |   (0/196):Loss 0.0517 Prec@1(1,5) 98.44, 100.00
11/03 03:57:41 AM |   (50/196):Loss 0.0540 Prec@1(1,5) 98.23, 99.99
11/03 03:57:47 AM |   (100/196):Loss 0.0550 Prec@1(1,5) 98.16, 100.00
11/03 03:57:52 AM |   (150/196):Loss 0.0557 Prec@1(1,5) 98.20, 99.99
11/03 03:57:59 AM |  * Acc@1 91.850 Acc@5 99.620
11/03 03:57:59 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 03:57:59 AM | ----
11/03 03:57:59 AM | Epoch[143]
11/03 03:57:59 AM | learning_rate: 0.0037475734366429476
11/03 03:58:00 AM |   (0/196):Loss 0.0553 Prec@1(1,5) 97.27, 100.00
11/03 03:58:06 AM |   (50/196):Loss 0.0513 Prec@1(1,5) 98.54, 99.99
11/03 03:58:11 AM |   (100/196):Loss 0.0517 Prec@1(1,5) 98.55, 99.99
11/03 03:58:17 AM |   (150/196):Loss 0.0529 Prec@1(1,5) 98.43, 99.99
11/03 03:58:24 AM |  * Acc@1 90.930 Acc@5 99.600
11/03 03:58:24 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 03:58:24 AM | ----
11/03 03:58:24 AM | Epoch[144]
11/03 03:58:24 AM | learning_rate: 0.003625760102513102
11/03 03:58:24 AM |   (0/196):Loss 0.0700 Prec@1(1,5) 97.66, 100.00
11/03 03:58:30 AM |   (50/196):Loss 0.0517 Prec@1(1,5) 98.38, 100.00
11/03 03:58:36 AM |   (100/196):Loss 0.0553 Prec@1(1,5) 98.28, 99.99
11/03 03:58:41 AM |   (150/196):Loss 0.0560 Prec@1(1,5) 98.28, 99.99
11/03 03:58:48 AM |  * Acc@1 91.130 Acc@5 99.710
11/03 03:58:48 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 03:58:48 AM | ----
11/03 03:58:48 AM | Epoch[145]
11/03 03:58:48 AM | learning_rate: 0.003505519516698164
11/03 03:58:49 AM |   (0/196):Loss 0.0310 Prec@1(1,5) 99.22, 100.00
11/03 03:58:55 AM |   (50/196):Loss 0.0530 Prec@1(1,5) 98.38, 100.00
11/03 03:59:00 AM |   (100/196):Loss 0.0529 Prec@1(1,5) 98.39, 99.99
11/03 03:59:06 AM |   (150/196):Loss 0.0539 Prec@1(1,5) 98.37, 99.99
11/03 03:59:13 AM |  * Acc@1 91.060 Acc@5 99.630
11/03 03:59:13 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 03:59:13 AM | ----
11/03 03:59:13 AM | Epoch[146]
11/03 03:59:13 AM | learning_rate: 0.0033868813467634825
11/03 03:59:13 AM |   (0/196):Loss 0.0439 Prec@1(1,5) 98.83, 100.00
11/03 03:59:19 AM |   (50/196):Loss 0.0520 Prec@1(1,5) 98.35, 99.99
11/03 03:59:24 AM |   (100/196):Loss 0.0521 Prec@1(1,5) 98.43, 99.99
11/03 03:59:30 AM |   (150/196):Loss 0.0529 Prec@1(1,5) 98.43, 99.98
11/03 03:59:37 AM |  * Acc@1 90.850 Acc@5 99.640
11/03 03:59:37 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 03:59:37 AM | ----
11/03 03:59:37 AM | Epoch[147]
11/03 03:59:37 AM | learning_rate: 0.0032698748649022656
11/03 03:59:38 AM |   (0/196):Loss 0.0757 Prec@1(1,5) 98.05, 100.00
11/03 03:59:43 AM |   (50/196):Loss 0.0488 Prec@1(1,5) 98.42, 100.00
11/03 03:59:49 AM |   (100/196):Loss 0.0463 Prec@1(1,5) 98.57, 99.99
11/03 03:59:55 AM |   (150/196):Loss 0.0471 Prec@1(1,5) 98.54, 99.99
11/03 04:00:02 AM |  * Acc@1 90.970 Acc@5 99.520
11/03 04:00:02 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 04:00:02 AM | ----
11/03 04:00:02 AM | Epoch[148]
11/03 04:00:02 AM | learning_rate: 0.0031545289407131126
11/03 04:00:02 AM |   (0/196):Loss 0.0400 Prec@1(1,5) 99.22, 100.00
11/03 04:00:08 AM |   (50/196):Loss 0.0427 Prec@1(1,5) 98.75, 100.00
11/03 04:00:14 AM |   (100/196):Loss 0.0435 Prec@1(1,5) 98.72, 100.00
11/03 04:00:19 AM |   (150/196):Loss 0.0454 Prec@1(1,5) 98.63, 100.00
11/03 04:00:26 AM |  * Acc@1 91.060 Acc@5 99.560
11/03 04:00:26 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 04:00:26 AM | ----
11/03 04:00:26 AM | Epoch[149]
11/03 04:00:26 AM | learning_rate: 0.003040872034076857
11/03 04:00:27 AM |   (0/196):Loss 0.0743 Prec@1(1,5) 97.66, 100.00
11/03 04:00:32 AM |   (50/196):Loss 0.0497 Prec@1(1,5) 98.46, 99.99
11/03 04:00:38 AM |   (100/196):Loss 0.0458 Prec@1(1,5) 98.57, 100.00
11/03 04:00:43 AM |   (150/196):Loss 0.0461 Prec@1(1,5) 98.55, 100.00
11/03 04:00:50 AM |  * Acc@1 91.520 Acc@5 99.680
11/03 04:00:51 AM | =>Best accuracy 91.850 (at epoch 142)
11/03 04:00:51 AM | ----
11/03 04:00:51 AM | Epoch[150]
11/03 04:00:51 AM | learning_rate: 0.0029289321881345253
11/03 04:00:51 AM |   (0/196):Loss 0.0255 Prec@1(1,5) 99.61, 100.00
11/03 04:00:57 AM |   (50/196):Loss 0.0434 Prec@1(1,5) 98.64, 100.00
11/03 04:01:02 AM |   (100/196):Loss 0.0438 Prec@1(1,5) 98.65, 100.00
11/03 04:01:08 AM |   (150/196):Loss 0.0442 Prec@1(1,5) 98.65, 100.00
11/03 04:01:15 AM |  * Acc@1 92.000 Acc@5 99.660
11/03 04:01:15 AM | =>Best accuracy 92.000 (at epoch 150)
11/03 04:01:15 AM | ----
11/03 04:01:15 AM | Epoch[151]
11/03 04:01:15 AM | learning_rate: 0.002818737022368113
11/03 04:01:16 AM |   (0/196):Loss 0.0285 Prec@1(1,5) 99.22, 100.00
11/03 04:01:21 AM |   (50/196):Loss 0.0342 Prec@1(1,5) 99.02, 99.99
11/03 04:01:27 AM |   (100/196):Loss 0.0374 Prec@1(1,5) 98.80, 100.00
11/03 04:01:32 AM |   (150/196):Loss 0.0398 Prec@1(1,5) 98.74, 100.00
11/03 04:01:40 AM |  * Acc@1 91.510 Acc@5 99.460
11/03 04:01:40 AM | =>Best accuracy 92.000 (at epoch 150)
11/03 04:01:40 AM | ----
11/03 04:01:40 AM | Epoch[152]
11/03 04:01:40 AM | learning_rate: 0.0027103137257858865
11/03 04:01:40 AM |   (0/196):Loss 0.0851 Prec@1(1,5) 97.27, 99.61
11/03 04:01:46 AM |   (50/196):Loss 0.0458 Prec@1(1,5) 98.58, 99.98
11/03 04:01:52 AM |   (100/196):Loss 0.0430 Prec@1(1,5) 98.72, 99.99
11/03 04:01:57 AM |   (150/196):Loss 0.0403 Prec@1(1,5) 98.79, 99.99
11/03 04:02:04 AM |  * Acc@1 92.540 Acc@5 99.730
11/03 04:02:04 AM | =>Best accuracy 92.540 (at epoch 152)
11/03 04:02:04 AM | ----
11/03 04:02:04 AM | Epoch[153]
11/03 04:02:04 AM | learning_rate: 0.002603689050213902
11/03 04:02:05 AM |   (0/196):Loss 0.0563 Prec@1(1,5) 98.44, 100.00
11/03 04:02:10 AM |   (50/196):Loss 0.0336 Prec@1(1,5) 99.05, 100.00
11/03 04:02:16 AM |   (100/196):Loss 0.0325 Prec@1(1,5) 99.08, 100.00
11/03 04:02:21 AM |   (150/196):Loss 0.0342 Prec@1(1,5) 99.01, 100.00
11/03 04:02:28 AM |  * Acc@1 92.400 Acc@5 99.670
11/03 04:02:29 AM | =>Best accuracy 92.540 (at epoch 152)
11/03 04:02:29 AM | ----
11/03 04:02:29 AM | Epoch[154]
11/03 04:02:29 AM | learning_rate: 0.0024988893036954037
11/03 04:02:29 AM |   (0/196):Loss 0.0153 Prec@1(1,5) 100.00, 100.00
11/03 04:02:35 AM |   (50/196):Loss 0.0366 Prec@1(1,5) 98.95, 100.00
11/03 04:02:40 AM |   (100/196):Loss 0.0360 Prec@1(1,5) 98.94, 100.00
11/03 04:02:46 AM |   (150/196):Loss 0.0359 Prec@1(1,5) 98.93, 100.00
11/03 04:02:53 AM |  * Acc@1 92.020 Acc@5 99.710
11/03 04:02:53 AM | =>Best accuracy 92.540 (at epoch 152)
11/03 04:02:53 AM | ----
11/03 04:02:53 AM | Epoch[155]
11/03 04:02:53 AM | learning_rate: 0.0023959403439996903
11/03 04:02:54 AM |   (0/196):Loss 0.0326 Prec@1(1,5) 99.22, 100.00
11/03 04:02:59 AM |   (50/196):Loss 0.0299 Prec@1(1,5) 99.12, 100.00
11/03 04:03:05 AM |   (100/196):Loss 0.0302 Prec@1(1,5) 99.10, 100.00
11/03 04:03:11 AM |   (150/196):Loss 0.0328 Prec@1(1,5) 99.01, 100.00
11/03 04:03:18 AM |  * Acc@1 92.320 Acc@5 99.690
11/03 04:03:18 AM | =>Best accuracy 92.540 (at epoch 152)
11/03 04:03:18 AM | ----
11/03 04:03:18 AM | Epoch[156]
11/03 04:03:18 AM | learning_rate: 0.002294867572242108
11/03 04:03:18 AM |   (0/196):Loss 0.0214 Prec@1(1,5) 99.61, 100.00
11/03 04:03:24 AM |   (50/196):Loss 0.0327 Prec@1(1,5) 99.00, 99.99
11/03 04:03:29 AM |   (100/196):Loss 0.0321 Prec@1(1,5) 99.05, 100.00
11/03 04:03:35 AM |   (150/196):Loss 0.0318 Prec@1(1,5) 99.06, 100.00
11/03 04:03:42 AM |  * Acc@1 92.650 Acc@5 99.700
11/03 04:03:42 AM | =>Best accuracy 92.650 (at epoch 156)
11/03 04:03:42 AM | ----
11/03 04:03:42 AM | Epoch[157]
11/03 04:03:42 AM | learning_rate: 0.002195695926616704
11/03 04:03:43 AM |   (0/196):Loss 0.0307 Prec@1(1,5) 98.83, 100.00
11/03 04:03:49 AM |   (50/196):Loss 0.0265 Prec@1(1,5) 99.25, 100.00
11/03 04:03:54 AM |   (100/196):Loss 0.0276 Prec@1(1,5) 99.19, 100.00
11/03 04:04:00 AM |   (150/196):Loss 0.0286 Prec@1(1,5) 99.20, 99.99
11/03 04:04:07 AM |  * Acc@1 92.470 Acc@5 99.610
11/03 04:04:07 AM | =>Best accuracy 92.650 (at epoch 156)
11/03 04:04:07 AM | ----
11/03 04:04:07 AM | Epoch[158]
11/03 04:04:07 AM | learning_rate: 0.0020984498762430955
11/03 04:04:07 AM |   (0/196):Loss 0.0416 Prec@1(1,5) 98.05, 100.00
11/03 04:04:13 AM |   (50/196):Loss 0.0358 Prec@1(1,5) 99.00, 99.99
11/03 04:04:19 AM |   (100/196):Loss 0.0317 Prec@1(1,5) 99.10, 100.00
11/03 04:04:24 AM |   (150/196):Loss 0.0297 Prec@1(1,5) 99.15, 100.00
11/03 04:04:31 AM |  * Acc@1 92.770 Acc@5 99.680
11/03 04:04:31 AM | =>Best accuracy 92.770 (at epoch 158)
11/03 04:04:31 AM | ----
11/03 04:04:31 AM | Epoch[159]
11/03 04:04:31 AM | learning_rate: 0.002003153415129094
11/03 04:04:32 AM |   (0/196):Loss 0.0122 Prec@1(1,5) 99.61, 100.00
11/03 04:04:38 AM |   (50/196):Loss 0.0201 Prec@1(1,5) 99.39, 100.00
11/03 04:04:43 AM |   (100/196):Loss 0.0216 Prec@1(1,5) 99.36, 100.00
11/03 04:04:49 AM |   (150/196):Loss 0.0224 Prec@1(1,5) 99.36, 100.00
11/03 04:04:56 AM |  * Acc@1 92.050 Acc@5 99.670
11/03 04:04:56 AM | =>Best accuracy 92.770 (at epoch 158)
11/03 04:04:56 AM | ----
11/03 04:04:56 AM | Epoch[160]
11/03 04:04:56 AM | learning_rate: 0.0019098300562505265
11/03 04:04:56 AM |   (0/196):Loss 0.0197 Prec@1(1,5) 99.61, 100.00
11/03 04:05:02 AM |   (50/196):Loss 0.0206 Prec@1(1,5) 99.48, 100.00
11/03 04:05:07 AM |   (100/196):Loss 0.0208 Prec@1(1,5) 99.46, 100.00
11/03 04:05:13 AM |   (150/196):Loss 0.0232 Prec@1(1,5) 99.36, 100.00
11/03 04:05:20 AM |  * Acc@1 92.740 Acc@5 99.690
11/03 04:05:20 AM | =>Best accuracy 92.770 (at epoch 158)
11/03 04:05:20 AM | ----
11/03 04:05:20 AM | Epoch[161]
11/03 04:05:20 AM | learning_rate: 0.001818502825749767
11/03 04:05:21 AM |   (0/196):Loss 0.0176 Prec@1(1,5) 99.61, 100.00
11/03 04:05:26 AM |   (50/196):Loss 0.0207 Prec@1(1,5) 99.51, 100.00
11/03 04:05:32 AM |   (100/196):Loss 0.0208 Prec@1(1,5) 99.50, 100.00
11/03 04:05:38 AM |   (150/196):Loss 0.0212 Prec@1(1,5) 99.49, 100.00
11/03 04:05:45 AM |  * Acc@1 92.950 Acc@5 99.630
11/03 04:05:45 AM | =>Best accuracy 92.950 (at epoch 161)
11/03 04:05:45 AM | ----
11/03 04:05:45 AM | Epoch[162]
11/03 04:05:45 AM | learning_rate: 0.0017291942572543828
11/03 04:05:46 AM |   (0/196):Loss 0.0115 Prec@1(1,5) 100.00, 100.00
11/03 04:05:51 AM |   (50/196):Loss 0.0214 Prec@1(1,5) 99.39, 99.99
11/03 04:05:57 AM |   (100/196):Loss 0.0214 Prec@1(1,5) 99.41, 100.00
11/03 04:06:02 AM |   (150/196):Loss 0.0206 Prec@1(1,5) 99.44, 100.00
11/03 04:06:09 AM |  * Acc@1 93.080 Acc@5 99.650
11/03 04:06:09 AM | =>Best accuracy 93.080 (at epoch 162)
11/03 04:06:09 AM | ----
11/03 04:06:09 AM | Epoch[163]
11/03 04:06:09 AM | learning_rate: 0.0016419263863172995
11/03 04:06:10 AM |   (0/196):Loss 0.0116 Prec@1(1,5) 99.61, 100.00
11/03 04:06:16 AM |   (50/196):Loss 0.0190 Prec@1(1,5) 99.47, 100.00
11/03 04:06:21 AM |   (100/196):Loss 0.0180 Prec@1(1,5) 99.55, 100.00
11/03 04:06:27 AM |   (150/196):Loss 0.0195 Prec@1(1,5) 99.50, 100.00
11/03 04:06:34 AM |  * Acc@1 92.890 Acc@5 99.700
11/03 04:06:34 AM | =>Best accuracy 93.080 (at epoch 162)
11/03 04:06:34 AM | ----
11/03 04:06:34 AM | Epoch[164]
11/03 04:06:34 AM | learning_rate: 0.0015567207449798514
11/03 04:06:34 AM |   (0/196):Loss 0.0159 Prec@1(1,5) 99.22, 100.00
11/03 04:06:40 AM |   (50/196):Loss 0.0183 Prec@1(1,5) 99.53, 100.00
11/03 04:06:46 AM |   (100/196):Loss 0.0168 Prec@1(1,5) 99.60, 100.00
11/03 04:06:51 AM |   (150/196):Loss 0.0163 Prec@1(1,5) 99.62, 100.00
11/03 04:06:58 AM |  * Acc@1 93.070 Acc@5 99.670
11/03 04:06:58 AM | =>Best accuracy 93.080 (at epoch 162)
11/03 04:06:58 AM | ----
11/03 04:06:58 AM | Epoch[165]
11/03 04:06:58 AM | learning_rate: 0.0014735983564590804
11/03 04:06:59 AM |   (0/196):Loss 0.0230 Prec@1(1,5) 99.22, 100.00
11/03 04:07:04 AM |   (50/196):Loss 0.0182 Prec@1(1,5) 99.46, 100.00
11/03 04:07:10 AM |   (100/196):Loss 0.0176 Prec@1(1,5) 99.50, 100.00
11/03 04:07:16 AM |   (150/196):Loss 0.0166 Prec@1(1,5) 99.56, 100.00
11/03 04:07:22 AM |  * Acc@1 92.900 Acc@5 99.690
11/03 04:07:23 AM | =>Best accuracy 93.080 (at epoch 162)
11/03 04:07:23 AM | ----
11/03 04:07:23 AM | Epoch[166]
11/03 04:07:23 AM | learning_rate: 0.0013925797299605624
11/03 04:07:23 AM |   (0/196):Loss 0.0035 Prec@1(1,5) 100.00, 100.00
11/03 04:07:29 AM |   (50/196):Loss 0.0178 Prec@1(1,5) 99.53, 99.98
11/03 04:07:34 AM |   (100/196):Loss 0.0176 Prec@1(1,5) 99.53, 99.99
11/03 04:07:40 AM |   (150/196):Loss 0.0170 Prec@1(1,5) 99.57, 99.99
11/03 04:07:47 AM |  * Acc@1 93.170 Acc@5 99.730
11/03 04:07:47 AM | =>Best accuracy 93.170 (at epoch 166)
11/03 04:07:47 AM | ----
11/03 04:07:47 AM | Epoch[167]
11/03 04:07:47 AM | learning_rate: 0.0013136848556180869
11/03 04:07:47 AM |   (0/196):Loss 0.0123 Prec@1(1,5) 100.00, 100.00
11/03 04:07:53 AM |   (50/196):Loss 0.0140 Prec@1(1,5) 99.72, 100.00
11/03 04:07:59 AM |   (100/196):Loss 0.0121 Prec@1(1,5) 99.77, 100.00
11/03 04:08:04 AM |   (150/196):Loss 0.0124 Prec@1(1,5) 99.74, 100.00
11/03 04:08:11 AM |  * Acc@1 93.140 Acc@5 99.680
11/03 04:08:11 AM | =>Best accuracy 93.170 (at epoch 166)
11/03 04:08:11 AM | ----
11/03 04:08:11 AM | Epoch[168]
11/03 04:08:11 AM | learning_rate: 0.0012369331995613641
11/03 04:08:11 AM |   (0/196):Loss 0.0068 Prec@1(1,5) 100.00, 100.00
11/03 04:08:17 AM |   (50/196):Loss 0.0121 Prec@1(1,5) 99.74, 100.00
11/03 04:08:23 AM |   (100/196):Loss 0.0125 Prec@1(1,5) 99.73, 100.00
11/03 04:08:29 AM |   (150/196):Loss 0.0130 Prec@1(1,5) 99.71, 100.00
11/03 04:08:35 AM |  * Acc@1 93.670 Acc@5 99.660
11/03 04:08:36 AM | =>Best accuracy 93.670 (at epoch 168)
11/03 04:08:36 AM | ----
11/03 04:08:36 AM | Epoch[169]
11/03 04:08:36 AM | learning_rate: 0.0011623436991130653
11/03 04:08:36 AM |   (0/196):Loss 0.0082 Prec@1(1,5) 100.00, 100.00
11/03 04:08:42 AM |   (50/196):Loss 0.0124 Prec@1(1,5) 99.69, 100.00
11/03 04:08:47 AM |   (100/196):Loss 0.0121 Prec@1(1,5) 99.72, 100.00
11/03 04:08:53 AM |   (150/196):Loss 0.0116 Prec@1(1,5) 99.75, 100.00
11/03 04:09:00 AM |  * Acc@1 93.530 Acc@5 99.740
11/03 04:09:00 AM | =>Best accuracy 93.670 (at epoch 168)
11/03 04:09:00 AM | ----
11/03 04:09:00 AM | Epoch[170]
11/03 04:09:00 AM | learning_rate: 0.0010899347581163222
11/03 04:09:01 AM |   (0/196):Loss 0.0105 Prec@1(1,5) 99.61, 100.00
11/03 04:09:06 AM |   (50/196):Loss 0.0129 Prec@1(1,5) 99.72, 100.00
11/03 04:09:12 AM |   (100/196):Loss 0.0112 Prec@1(1,5) 99.78, 100.00
11/03 04:09:18 AM |   (150/196):Loss 0.0103 Prec@1(1,5) 99.81, 100.00
11/03 04:09:25 AM |  * Acc@1 93.590 Acc@5 99.710
11/03 04:09:25 AM | =>Best accuracy 93.670 (at epoch 168)
11/03 04:09:25 AM | ----
11/03 04:09:25 AM | Epoch[171]
11/03 04:09:25 AM | learning_rate: 0.0010197242423938446
11/03 04:09:25 AM |   (0/196):Loss 0.0099 Prec@1(1,5) 99.61, 100.00
11/03 04:09:31 AM |   (50/196):Loss 0.0116 Prec@1(1,5) 99.74, 100.00
11/03 04:09:37 AM |   (100/196):Loss 0.0107 Prec@1(1,5) 99.80, 100.00
11/03 04:09:42 AM |   (150/196):Loss 0.0108 Prec@1(1,5) 99.79, 100.00
11/03 04:09:49 AM |  * Acc@1 93.700 Acc@5 99.680
11/03 04:09:49 AM | =>Best accuracy 93.700 (at epoch 171)
11/03 04:09:49 AM | ----
11/03 04:09:49 AM | Epoch[172]
11/03 04:09:49 AM | learning_rate: 0.0009517294753398064
11/03 04:09:50 AM |   (0/196):Loss 0.0077 Prec@1(1,5) 100.00, 100.00
11/03 04:09:55 AM |   (50/196):Loss 0.0107 Prec@1(1,5) 99.78, 100.00
11/03 04:10:01 AM |   (100/196):Loss 0.0110 Prec@1(1,5) 99.75, 100.00
11/03 04:10:07 AM |   (150/196):Loss 0.0108 Prec@1(1,5) 99.76, 100.00
11/03 04:10:14 AM |  * Acc@1 93.530 Acc@5 99.650
11/03 04:10:14 AM | =>Best accuracy 93.700 (at epoch 171)
11/03 04:10:14 AM | ----
11/03 04:10:14 AM | Epoch[173]
11/03 04:10:14 AM | learning_rate: 0.0008859672336455493
11/03 04:10:14 AM |   (0/196):Loss 0.0042 Prec@1(1,5) 100.00, 100.00
11/03 04:10:20 AM |   (50/196):Loss 0.0089 Prec@1(1,5) 99.82, 100.00
11/03 04:10:26 AM |   (100/196):Loss 0.0094 Prec@1(1,5) 99.81, 100.00
11/03 04:10:31 AM |   (150/196):Loss 0.0093 Prec@1(1,5) 99.81, 100.00
11/03 04:10:38 AM |  * Acc@1 93.560 Acc@5 99.750
11/03 04:10:38 AM | =>Best accuracy 93.700 (at epoch 171)
11/03 04:10:38 AM | ----
11/03 04:10:38 AM | Epoch[174]
11/03 04:10:38 AM | learning_rate: 0.0008224537431601908
11/03 04:10:39 AM |   (0/196):Loss 0.0043 Prec@1(1,5) 100.00, 100.00
11/03 04:10:44 AM |   (50/196):Loss 0.0076 Prec@1(1,5) 99.90, 100.00
11/03 04:10:50 AM |   (100/196):Loss 0.0074 Prec@1(1,5) 99.90, 100.00
11/03 04:10:56 AM |   (150/196):Loss 0.0077 Prec@1(1,5) 99.89, 100.00
11/03 04:11:02 AM |  * Acc@1 93.670 Acc@5 99.680
11/03 04:11:02 AM | =>Best accuracy 93.700 (at epoch 171)
11/03 04:11:02 AM | ----
11/03 04:11:02 AM | Epoch[175]
11/03 04:11:02 AM | learning_rate: 0.0007612046748871348
11/03 04:11:03 AM |   (0/196):Loss 0.0069 Prec@1(1,5) 100.00, 100.00
11/03 04:11:09 AM |   (50/196):Loss 0.0072 Prec@1(1,5) 99.89, 100.00
11/03 04:11:14 AM |   (100/196):Loss 0.0080 Prec@1(1,5) 99.86, 100.00
11/03 04:11:20 AM |   (150/196):Loss 0.0080 Prec@1(1,5) 99.87, 100.00
11/03 04:11:27 AM |  * Acc@1 93.780 Acc@5 99.690
11/03 04:11:27 AM | =>Best accuracy 93.780 (at epoch 175)
11/03 04:11:27 AM | ----
11/03 04:11:27 AM | Epoch[176]
11/03 04:11:27 AM | learning_rate: 0.0007022351411174865
11/03 04:11:27 AM |   (0/196):Loss 0.0113 Prec@1(1,5) 99.61, 100.00
11/03 04:11:33 AM |   (50/196):Loss 0.0088 Prec@1(1,5) 99.84, 100.00
11/03 04:11:39 AM |   (100/196):Loss 0.0082 Prec@1(1,5) 99.87, 100.00
11/03 04:11:44 AM |   (150/196):Loss 0.0081 Prec@1(1,5) 99.87, 100.00
11/03 04:11:51 AM |  * Acc@1 93.650 Acc@5 99.710
11/03 04:11:51 AM | =>Best accuracy 93.780 (at epoch 175)
11/03 04:11:51 AM | ----
11/03 04:11:51 AM | Epoch[177]
11/03 04:11:51 AM | learning_rate: 0.0006455596917013262
11/03 04:11:52 AM |   (0/196):Loss 0.0071 Prec@1(1,5) 100.00, 100.00
11/03 04:11:58 AM |   (50/196):Loss 0.0069 Prec@1(1,5) 99.90, 100.00
11/03 04:12:03 AM |   (100/196):Loss 0.0071 Prec@1(1,5) 99.89, 100.00
11/03 04:12:09 AM |   (150/196):Loss 0.0070 Prec@1(1,5) 99.89, 100.00
11/03 04:12:16 AM |  * Acc@1 93.790 Acc@5 99.740
11/03 04:12:16 AM | =>Best accuracy 93.790 (at epoch 177)
11/03 04:12:16 AM | ----
11/03 04:12:16 AM | Epoch[178]
11/03 04:12:16 AM | learning_rate: 0.0005911923104577454
11/03 04:12:17 AM |   (0/196):Loss 0.0298 Prec@1(1,5) 98.83, 100.00
11/03 04:12:22 AM |   (50/196):Loss 0.0078 Prec@1(1,5) 99.88, 100.00
11/03 04:12:28 AM |   (100/196):Loss 0.0070 Prec@1(1,5) 99.90, 100.00
11/03 04:12:33 AM |   (150/196):Loss 0.0069 Prec@1(1,5) 99.90, 100.00
11/03 04:12:40 AM |  * Acc@1 93.690 Acc@5 99.770
11/03 04:12:40 AM | =>Best accuracy 93.790 (at epoch 177)
11/03 04:12:40 AM | ----
11/03 04:12:40 AM | Epoch[179]
11/03 04:12:40 AM | learning_rate: 0.0005391464117245469
11/03 04:12:41 AM |   (0/196):Loss 0.0062 Prec@1(1,5) 100.00, 100.00
11/03 04:12:47 AM |   (50/196):Loss 0.0068 Prec@1(1,5) 99.92, 100.00
11/03 04:12:52 AM |   (100/196):Loss 0.0065 Prec@1(1,5) 99.91, 100.00
11/03 04:12:58 AM |   (150/196):Loss 0.0064 Prec@1(1,5) 99.91, 100.00
11/03 04:13:05 AM |  * Acc@1 93.900 Acc@5 99.750
11/03 04:13:05 AM | =>Best accuracy 93.900 (at epoch 179)
11/03 04:13:05 AM | ----
11/03 04:13:05 AM | Epoch[180]
11/03 04:13:05 AM | learning_rate: 0.0004894348370484646
11/03 04:13:05 AM |   (0/196):Loss 0.0046 Prec@1(1,5) 100.00, 100.00
11/03 04:13:11 AM |   (50/196):Loss 0.0055 Prec@1(1,5) 99.94, 100.00
11/03 04:13:17 AM |   (100/196):Loss 0.0058 Prec@1(1,5) 99.93, 100.00
11/03 04:13:22 AM |   (150/196):Loss 0.0062 Prec@1(1,5) 99.93, 100.00
11/03 04:13:29 AM |  * Acc@1 93.840 Acc@5 99.740
11/03 04:13:29 AM | =>Best accuracy 93.900 (at epoch 179)
11/03 04:13:29 AM | ----
11/03 04:13:29 AM | Epoch[181]
11/03 04:13:29 AM | learning_rate: 0.0004420698520166987
11/03 04:13:30 AM |   (0/196):Loss 0.0071 Prec@1(1,5) 100.00, 100.00
11/03 04:13:36 AM |   (50/196):Loss 0.0058 Prec@1(1,5) 99.93, 100.00
11/03 04:13:41 AM |   (100/196):Loss 0.0057 Prec@1(1,5) 99.94, 100.00
11/03 04:13:47 AM |   (150/196):Loss 0.0055 Prec@1(1,5) 99.95, 100.00
11/03 04:13:54 AM |  * Acc@1 93.900 Acc@5 99.760
11/03 04:13:54 AM | =>Best accuracy 93.900 (at epoch 179)
11/03 04:13:54 AM | ----
11/03 04:13:54 AM | Epoch[182]
11/03 04:13:54 AM | learning_rate: 0.0003970631432305704
11/03 04:13:54 AM |   (0/196):Loss 0.0052 Prec@1(1,5) 100.00, 100.00
11/03 04:14:00 AM |   (50/196):Loss 0.0079 Prec@1(1,5) 99.87, 100.00
11/03 04:14:06 AM |   (100/196):Loss 0.0066 Prec@1(1,5) 99.91, 100.00
11/03 04:14:11 AM |   (150/196):Loss 0.0063 Prec@1(1,5) 99.92, 100.00
11/03 04:14:18 AM |  * Acc@1 94.040 Acc@5 99.740
11/03 04:14:18 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:14:18 AM | ----
11/03 04:14:18 AM | Epoch[183]
11/03 04:14:18 AM | learning_rate: 0.0003544258154220203
11/03 04:14:19 AM |   (0/196):Loss 0.0035 Prec@1(1,5) 100.00, 100.00
11/03 04:14:24 AM |   (50/196):Loss 0.0068 Prec@1(1,5) 99.92, 100.00
11/03 04:14:30 AM |   (100/196):Loss 0.0062 Prec@1(1,5) 99.92, 100.00
11/03 04:14:35 AM |   (150/196):Loss 0.0059 Prec@1(1,5) 99.93, 100.00
11/03 04:14:42 AM |  * Acc@1 93.940 Acc@5 99.790
11/03 04:14:42 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:14:42 AM | ----
11/03 04:14:42 AM | Epoch[184]
11/03 04:14:42 AM | learning_rate: 0.0003141683887136903
11/03 04:14:43 AM |   (0/196):Loss 0.0032 Prec@1(1,5) 100.00, 100.00
11/03 04:14:49 AM |   (50/196):Loss 0.0055 Prec@1(1,5) 99.95, 100.00
11/03 04:14:54 AM |   (100/196):Loss 0.0053 Prec@1(1,5) 99.96, 100.00
11/03 04:15:00 AM |   (150/196):Loss 0.0053 Prec@1(1,5) 99.95, 100.00
11/03 04:15:07 AM |  * Acc@1 93.970 Acc@5 99.750
11/03 04:15:07 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:15:07 AM | ----
11/03 04:15:07 AM | Epoch[185]
11/03 04:15:07 AM | learning_rate: 0.0002763007960232344
11/03 04:15:07 AM |   (0/196):Loss 0.0036 Prec@1(1,5) 100.00, 100.00
11/03 04:15:13 AM |   (50/196):Loss 0.0054 Prec@1(1,5) 99.95, 100.00
11/03 04:15:19 AM |   (100/196):Loss 0.0055 Prec@1(1,5) 99.94, 100.00
11/03 04:15:24 AM |   (150/196):Loss 0.0056 Prec@1(1,5) 99.94, 100.00
11/03 04:15:31 AM |  * Acc@1 93.910 Acc@5 99.750
11/03 04:15:31 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:15:31 AM | ----
11/03 04:15:31 AM | Epoch[186]
11/03 04:15:31 AM | learning_rate: 0.00024083238061252673
11/03 04:15:32 AM |   (0/196):Loss 0.0033 Prec@1(1,5) 100.00, 100.00
11/03 04:15:38 AM |   (50/196):Loss 0.0051 Prec@1(1,5) 99.95, 100.00
11/03 04:15:43 AM |   (100/196):Loss 0.0054 Prec@1(1,5) 99.95, 100.00
11/03 04:15:49 AM |   (150/196):Loss 0.0054 Prec@1(1,5) 99.95, 100.00
11/03 04:15:55 AM |  * Acc@1 93.900 Acc@5 99.720
11/03 04:15:56 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:15:56 AM | ----
11/03 04:15:56 AM | Epoch[187]
11/03 04:15:56 AM | learning_rate: 0.00020777189378234136
11/03 04:15:56 AM |   (0/196):Loss 0.0040 Prec@1(1,5) 100.00, 100.00
11/03 04:16:02 AM |   (50/196):Loss 0.0056 Prec@1(1,5) 99.92, 100.00
11/03 04:16:08 AM |   (100/196):Loss 0.0057 Prec@1(1,5) 99.93, 100.00
11/03 04:16:13 AM |   (150/196):Loss 0.0056 Prec@1(1,5) 99.92, 100.00
11/03 04:16:20 AM |  * Acc@1 93.970 Acc@5 99.730
11/03 04:16:20 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:16:20 AM | ----
11/03 04:16:20 AM | Epoch[188]
11/03 04:16:20 AM | learning_rate: 0.00017712749271311275
11/03 04:16:21 AM |   (0/196):Loss 0.0030 Prec@1(1,5) 100.00, 100.00
11/03 04:16:26 AM |   (50/196):Loss 0.0057 Prec@1(1,5) 99.95, 100.00
11/03 04:16:32 AM |   (100/196):Loss 0.0053 Prec@1(1,5) 99.95, 100.00
11/03 04:16:38 AM |   (150/196):Loss 0.0055 Prec@1(1,5) 99.94, 100.00
11/03 04:16:44 AM |  * Acc@1 93.990 Acc@5 99.770
11/03 04:16:45 AM | =>Best accuracy 94.040 (at epoch 182)
11/03 04:16:45 AM | ----
11/03 04:16:45 AM | Epoch[189]
11/03 04:16:45 AM | learning_rate: 0.00014890673845226128
11/03 04:16:45 AM |   (0/196):Loss 0.0034 Prec@1(1,5) 100.00, 100.00
11/03 04:16:51 AM |   (50/196):Loss 0.0050 Prec@1(1,5) 99.95, 100.00
11/03 04:16:56 AM |   (100/196):Loss 0.0051 Prec@1(1,5) 99.94, 100.00
11/03 04:17:02 AM |   (150/196):Loss 0.0049 Prec@1(1,5) 99.95, 100.00
11/03 04:17:09 AM |  * Acc@1 94.090 Acc@5 99.710
11/03 04:17:09 AM | =>Best accuracy 94.090 (at epoch 189)
11/03 04:17:09 AM | ----
11/03 04:17:09 AM | Epoch[190]
11/03 04:17:09 AM | learning_rate: 0.00012311659404862338
11/03 04:17:09 AM |   (0/196):Loss 0.0038 Prec@1(1,5) 100.00, 100.00
11/03 04:17:15 AM |   (50/196):Loss 0.0050 Prec@1(1,5) 99.94, 100.00
11/03 04:17:21 AM |   (100/196):Loss 0.0049 Prec@1(1,5) 99.95, 100.00
11/03 04:17:26 AM |   (150/196):Loss 0.0047 Prec@1(1,5) 99.96, 100.00
11/03 04:17:33 AM |  * Acc@1 93.950 Acc@5 99.730
11/03 04:17:33 AM | =>Best accuracy 94.090 (at epoch 189)
11/03 04:17:33 AM | ----
11/03 04:17:33 AM | Epoch[191]
11/03 04:17:33 AM | learning_rate: 9.976342283442462e-05
11/03 04:17:34 AM |   (0/196):Loss 0.0034 Prec@1(1,5) 100.00, 100.00
11/03 04:17:40 AM |   (50/196):Loss 0.0052 Prec@1(1,5) 99.95, 100.00
11/03 04:17:45 AM |   (100/196):Loss 0.0050 Prec@1(1,5) 99.95, 100.00
11/03 04:17:51 AM |   (150/196):Loss 0.0050 Prec@1(1,5) 99.96, 100.00
11/03 04:17:58 AM |  * Acc@1 94.150 Acc@5 99.730
11/03 04:17:58 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:17:58 AM | ----
11/03 04:17:58 AM | Epoch[192]
11/03 04:17:58 AM | learning_rate: 7.885298685522235e-05
11/03 04:17:58 AM |   (0/196):Loss 0.0052 Prec@1(1,5) 100.00, 100.00
11/03 04:18:04 AM |   (50/196):Loss 0.0054 Prec@1(1,5) 99.94, 100.00
11/03 04:18:10 AM |   (100/196):Loss 0.0052 Prec@1(1,5) 99.94, 100.00
11/03 04:18:15 AM |   (150/196):Loss 0.0051 Prec@1(1,5) 99.95, 100.00
11/03 04:18:22 AM |  * Acc@1 94.060 Acc@5 99.730
11/03 04:18:22 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:18:22 AM | ----
11/03 04:18:22 AM | Epoch[193]
11/03 04:18:22 AM | learning_rate: 6.0390445448204035e-05
11/03 04:18:23 AM |   (0/196):Loss 0.0040 Prec@1(1,5) 100.00, 100.00
11/03 04:18:28 AM |   (50/196):Loss 0.0047 Prec@1(1,5) 99.98, 100.00
11/03 04:18:34 AM |   (100/196):Loss 0.0048 Prec@1(1,5) 99.98, 100.00
11/03 04:18:40 AM |   (150/196):Loss 0.0048 Prec@1(1,5) 99.97, 100.00
11/03 04:18:46 AM |  * Acc@1 94.130 Acc@5 99.730
11/03 04:18:46 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:18:46 AM | ----
11/03 04:18:46 AM | Epoch[194]
11/03 04:18:46 AM | learning_rate: 4.4380353969200026e-05
11/03 04:18:47 AM |   (0/196):Loss 0.0044 Prec@1(1,5) 100.00, 100.00
11/03 04:18:53 AM |   (50/196):Loss 0.0053 Prec@1(1,5) 99.93, 100.00
11/03 04:18:58 AM |   (100/196):Loss 0.0055 Prec@1(1,5) 99.93, 100.00
11/03 04:19:04 AM |   (150/196):Loss 0.0051 Prec@1(1,5) 99.95, 100.00
11/03 04:19:11 AM |  * Acc@1 94.030 Acc@5 99.710
11/03 04:19:11 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:19:11 AM | ----
11/03 04:19:11 AM | Epoch[195]
11/03 04:19:11 AM | learning_rate: 3.082666266872035e-05
11/03 04:19:11 AM |   (0/196):Loss 0.0045 Prec@1(1,5) 100.00, 100.00
11/03 04:19:17 AM |   (50/196):Loss 0.0047 Prec@1(1,5) 99.98, 100.00
11/03 04:19:23 AM |   (100/196):Loss 0.0048 Prec@1(1,5) 99.97, 100.00
11/03 04:19:28 AM |   (150/196):Loss 0.0048 Prec@1(1,5) 99.96, 100.00
11/03 04:19:35 AM |  * Acc@1 94.040 Acc@5 99.710
11/03 04:19:35 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:19:35 AM | ----
11/03 04:19:35 AM | Epoch[196]
11/03 04:19:35 AM | learning_rate: 1.9732715717284406e-05
11/03 04:19:36 AM |   (0/196):Loss 0.0037 Prec@1(1,5) 100.00, 100.00
11/03 04:19:42 AM |   (50/196):Loss 0.0047 Prec@1(1,5) 99.96, 100.00
11/03 04:19:47 AM |   (100/196):Loss 0.0051 Prec@1(1,5) 99.95, 100.00
11/03 04:19:53 AM |   (150/196):Loss 0.0050 Prec@1(1,5) 99.95, 100.00
11/03 04:20:00 AM |  * Acc@1 94.030 Acc@5 99.740
11/03 04:20:00 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:20:00 AM | ----
11/03 04:20:00 AM | Epoch[197]
11/03 04:20:00 AM | learning_rate: 1.1101250380300961e-05
11/03 04:20:00 AM |   (0/196):Loss 0.0030 Prec@1(1,5) 100.00, 100.00
11/03 04:20:06 AM |   (50/196):Loss 0.0042 Prec@1(1,5) 99.99, 100.00
11/03 04:20:12 AM |   (100/196):Loss 0.0046 Prec@1(1,5) 99.98, 100.00
11/03 04:20:17 AM |   (150/196):Loss 0.0047 Prec@1(1,5) 99.97, 100.00
11/03 04:20:24 AM |  * Acc@1 94.010 Acc@5 99.690
11/03 04:20:24 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:20:24 AM | ----
11/03 04:20:24 AM | Epoch[198]
11/03 04:20:24 AM | learning_rate: 4.934396342683998e-06
11/03 04:20:25 AM |   (0/196):Loss 0.0034 Prec@1(1,5) 100.00, 100.00
11/03 04:20:31 AM |   (50/196):Loss 0.0048 Prec@1(1,5) 99.96, 100.00
11/03 04:20:36 AM |   (100/196):Loss 0.0046 Prec@1(1,5) 99.96, 100.00
11/03 04:20:42 AM |   (150/196):Loss 0.0049 Prec@1(1,5) 99.96, 100.00
11/03 04:20:48 AM |  * Acc@1 94.000 Acc@5 99.740
11/03 04:20:49 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:20:49 AM | ----
11/03 04:20:49 AM | Epoch[199]
11/03 04:20:49 AM | learning_rate: 1.2336751833941225e-06
11/03 04:20:49 AM |   (0/196):Loss 0.0056 Prec@1(1,5) 100.00, 100.00
11/03 04:20:55 AM |   (50/196):Loss 0.0047 Prec@1(1,5) 99.97, 100.00
11/03 04:21:01 AM |   (100/196):Loss 0.0046 Prec@1(1,5) 99.97, 100.00
11/03 04:21:06 AM |   (150/196):Loss 0.0046 Prec@1(1,5) 99.97, 100.00
11/03 04:21:13 AM |  * Acc@1 94.040 Acc@5 99.720
11/03 04:21:13 AM | =>Best accuracy 94.150 (at epoch 191)
11/03 04:21:13 AM | ----
11/03 04:22:05 AM | ----------------------------------------
11/03 04:22:05 AM | Performances input model:
11/03 04:22:05 AM |  - flops: 85,280,640
11/03 04:22:05 AM |  - params: 706,148
11/03 04:22:05 AM |  - accuracy: 84.3699951171875
11/03 04:22:05 AM | ----------------------------------------
11/03 04:22:05 AM | Performances finetuned model:
11/03 04:22:05 AM |  - flops: 85,280,640
11/03 04:22:05 AM |  - params: 706,148
11/03 04:22:05 AM |  - accuracy: 94.14999389648438
